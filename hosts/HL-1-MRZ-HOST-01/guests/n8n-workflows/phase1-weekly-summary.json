{
  "name": "Phase 1.1 â€“ WÃ¶chentliche KI-Zusammenfassung",
  "nodes": [
    {
      "parameters": {
        "rule": {
          "interval": [
            {
              "triggerAtHour": 21,
              "triggerAtDay": 7
            }
          ]
        }
      },
      "id": "a1b2c3d4-0001-4000-8000-000000000001",
      "name": "Sonntag 21:00",
      "type": "n8n-nodes-base.scheduleTrigger",
      "typeVersion": 1.2,
      "position": [0, 0]
    },
    {
      "parameters": {
        "method": "POST",
        "url": "http://10.15.40.112:8428/api/v1/query",
        "sendBody": true,
        "specifyBody": "json",
        "jsonBody": "{\n  \"query\": \"topk(10, max_over_time(process_resident_memory_bytes[7d])) / 1024 / 1024\"\n}",
        "options": {
          "timeout": 15000
        }
      },
      "id": "a1b2c3d4-0001-4000-8000-000000000002",
      "name": "VictoriaMetrics â€“ RAM Top 10",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [280, -200]
    },
    {
      "parameters": {
        "method": "POST",
        "url": "http://10.15.40.112:8428/api/v1/query",
        "sendBody": true,
        "specifyBody": "json",
        "jsonBody": "{\n  \"query\": \"(1 - avg_over_time(node_filesystem_avail_bytes{mountpoint=\\\"/\\\"}[7d]) / avg_over_time(node_filesystem_size_bytes{mountpoint=\\\"/\\\"}[7d])) * 100\"\n}",
        "options": {
          "timeout": 15000
        }
      },
      "id": "a1b2c3d4-0001-4000-8000-000000000003",
      "name": "VictoriaMetrics â€“ Disk Usage",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [280, 0]
    },
    {
      "parameters": {
        "method": "GET",
        "url": "http://10.15.40.111:3000/api/v1/provisioning/alert-rules",
        "authentication": "genericCredentialType",
        "genericAuthType": "httpHeaderAuth",
        "options": {
          "timeout": 15000
        }
      },
      "id": "a1b2c3d4-0001-4000-8000-000000000004",
      "name": "Grafana â€“ Alert Rules Status",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [280, 200],
      "credentials": {
        "httpHeaderAuth": {
          "id": "GRAFANA_CREDENTIAL_ID",
          "name": "Grafana API"
        }
      }
    },
    {
      "parameters": {
        "method": "GET",
        "url": "http://10.15.40.18:8000/api/v1/logstream",
        "authentication": "genericCredentialType",
        "genericAuthType": "httpBasicAuth",
        "options": {
          "timeout": 15000
        }
      },
      "id": "a1b2c3d4-0001-4000-8000-000000000005",
      "name": "Parseable â€“ Log Streams",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [280, 400],
      "credentials": {
        "httpBasicAuth": {
          "id": "PARSEABLE_CREDENTIAL_ID",
          "name": "Parseable API"
        }
      }
    },
    {
      "parameters": {
        "jsCode": "// Daten aus allen parallelen Quellen zusammenfÃ¼hren\nconst vmRam = $('VictoriaMetrics â€“ RAM Top 10').first().json;\nconst vmDisk = $('VictoriaMetrics â€“ Disk Usage').first().json;\nconst grafanaAlerts = $('Grafana â€“ Alert Rules Status').first().json;\nconst parseableLogs = $('Parseable â€“ Log Streams').first().json;\n\n// RAM-Daten aufbereiten\nlet ramSummary = 'Keine Daten';\ntry {\n  const ramResults = vmRam?.data?.result || [];\n  ramSummary = ramResults\n    .slice(0, 5)\n    .map(r => {\n      const job = r.metric?.job || r.metric?.instance || 'unknown';\n      const mb = Math.round(parseFloat(r.value?.[1] || 0));\n      return `  â€¢ ${job}: ${mb} MB`;\n    })\n    .join('\\n') || 'Keine Daten';\n} catch (e) {\n  ramSummary = 'Fehler beim Parsen: ' + e.message;\n}\n\n// Disk-Daten aufbereiten\nlet diskSummary = 'Keine Daten';\ntry {\n  const diskResults = vmDisk?.data?.result || [];\n  diskSummary = diskResults\n    .map(r => {\n      const instance = r.metric?.instance || 'unknown';\n      const pct = parseFloat(r.value?.[1] || 0).toFixed(1);\n      return `  â€¢ ${instance}: ${pct}%`;\n    })\n    .join('\\n') || 'Keine Daten';\n} catch (e) {\n  diskSummary = 'Fehler beim Parsen: ' + e.message;\n}\n\n// Alert-Daten\nlet alertSummary = 'Keine Daten';\ntry {\n  const alerts = Array.isArray(grafanaAlerts) ? grafanaAlerts : [];\n  const firing = alerts.filter(a => a.state === 'firing' || a.state === 'alerting');\n  const pending = alerts.filter(a => a.state === 'pending');\n  alertSummary = `  â€¢ Aktive Alerts: ${firing.length}\\n  â€¢ Pending: ${pending.length}\\n  â€¢ Gesamt konfiguriert: ${alerts.length}`;\n} catch (e) {\n  alertSummary = 'Fehler beim Parsen: ' + e.message;\n}\n\n// Log-Streams\nlet logSummary = 'Keine Daten';\ntry {\n  const streams = Array.isArray(parseableLogs) ? parseableLogs : [];\n  logSummary = `  â€¢ Aktive Log-Streams: ${streams.length}`;\n  if (streams.length > 0) {\n    logSummary += '\\n  â€¢ Streams: ' + streams.map(s => s.name || s).join(', ');\n  }\n} catch (e) {\n  logSummary = 'Fehler beim Parsen: ' + e.message;\n}\n\n// Kontext fÃ¼r Ollama aufbauen\nconst now = new Date();\nconst kw = getWeekNumber(now);\n\nfunction getWeekNumber(d) {\n  const onejan = new Date(d.getFullYear(), 0, 1);\n  return Math.ceil(((d - onejan) / 86400000 + onejan.getDay() + 1) / 7);\n}\n\nconst context = [\n  `=== Infrastruktur-Report KW ${kw} (${now.toISOString().split('T')[0]}) ===`,\n  '',\n  '--- RAM-Nutzung (Top 5, Peak der Woche) ---',\n  ramSummary,\n  '',\n  '--- Disk-Belegung ---',\n  diskSummary,\n  '',\n  '--- Grafana Alerts ---',\n  alertSummary,\n  '',\n  '--- Logging (Parseable) ---',\n  logSummary\n].join('\\n');\n\nreturn [{ json: { context, kw, date: now.toISOString().split('T')[0] } }];"
      },
      "id": "a1b2c3d4-0001-4000-8000-000000000006",
      "name": "Daten aggregieren",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [600, 100]
    },
    {
      "parameters": {
        "promptType": "define",
        "text": "={{ $json.context }}",
        "messages": {
          "values": [
            {
              "content": "Du bist ein erfahrener System-Administrator fÃ¼r ein Homelab mit NixOS-MicroVMs. Dein Job ist es, wÃ¶chentliche Status-Zusammenfassungen zu schreiben.\n\nRegeln:\n- Antworte auf Deutsch\n- Maximal 250 WÃ¶rter\n- Verwende Emoji fÃ¼r Kategorien (ðŸ“Š Metriken, ðŸ”´ Probleme, ðŸŸ¢ OK, ðŸ’¡ Empfehlungen)\n- Hebe kritische Probleme klar hervor\n- Gib am Ende 1-3 konkrete Handlungsempfehlungen\n- Falls Daten fehlen oder leer sind, erwÃ¤hne das kurz\n- Formatiere als kompakte Markdown-Nachricht (fÃ¼r ntfy Push)"
            }
          ]
        },
        "options": {
          "temperature": 0.3
        }
      },
      "id": "a1b2c3d4-0001-4000-8000-000000000007",
      "name": "Ollama â€“ Zusammenfassung",
      "type": "@n8n/n8n-nodes-langchain.lmChatOllama",
      "typeVersion": 1,
      "position": [900, 100],
      "credentials": {
        "ollamaApi": {
          "id": "OLLAMA_CREDENTIAL_ID",
          "name": "Ollama HOST-01"
        }
      }
    },
    {
      "parameters": {
        "model": "mistral:latest",
        "options": {}
      },
      "id": "a1b2c3d4-0001-4000-8000-000000000008",
      "name": "Ollama Model",
      "type": "@n8n/n8n-nodes-langchain.lmChatOllama",
      "typeVersion": 1,
      "position": [900, 300],
      "credentials": {
        "ollamaApi": {
          "id": "OLLAMA_CREDENTIAL_ID",
          "name": "Ollama HOST-01"
        }
      }
    },
    {
      "parameters": {
        "promptType": "define",
        "text": "Fasse die folgenden Infrastruktur-Daten meines Homelabs zusammen. Schreibe eine kompakte WochenÃ¼bersicht.\n\n{{ $('Daten aggregieren').first().json.context }}",
        "hasOutputParser": false,
        "options": {
          "temperature": 0.3
        }
      },
      "id": "a1b2c3d4-0001-4000-8000-000000000009",
      "name": "KI-Zusammenfassung generieren",
      "type": "@n8n/n8n-nodes-langchain.chainLlm",
      "typeVersion": 1.4,
      "position": [900, 100]
    },
    {
      "parameters": {
        "method": "POST",
        "url": "https://ntfy.czichy.com/homelab",
        "sendHeaders": true,
        "headerParameters": {
          "parameters": [
            {
              "name": "Title",
              "value": "ðŸ“‹ Wochenreport KW {{ $('Daten aggregieren').first().json.kw }}"
            },
            {
              "name": "Priority",
              "value": "3"
            },
            {
              "name": "Tags",
              "value": "chart_with_upwards_trend,robot"
            },
            {
              "name": "Markdown",
              "value": "yes"
            }
          ]
        },
        "sendBody": true,
        "specifyBody": "string",
        "body": "={{ $json.text || $json.output || $json.response || JSON.stringify($json) }}",
        "options": {
          "timeout": 10000
        }
      },
      "id": "a1b2c3d4-0001-4000-8000-00000000000a",
      "name": "ntfy â€“ Wochenreport senden",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [1200, 100]
    }
  ],
  "connections": {
    "Sonntag 21:00": {
      "main": [
        [
          {
            "node": "VictoriaMetrics â€“ RAM Top 10",
            "type": "main",
            "index": 0
          },
          {
            "node": "VictoriaMetrics â€“ Disk Usage",
            "type": "main",
            "index": 0
          },
          {
            "node": "Grafana â€“ Alert Rules Status",
            "type": "main",
            "index": 0
          },
          {
            "node": "Parseable â€“ Log Streams",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "VictoriaMetrics â€“ RAM Top 10": {
      "main": [
        [
          {
            "node": "Daten aggregieren",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "VictoriaMetrics â€“ Disk Usage": {
      "main": [
        [
          {
            "node": "Daten aggregieren",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Grafana â€“ Alert Rules Status": {
      "main": [
        [
          {
            "node": "Daten aggregieren",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Parseable â€“ Log Streams": {
      "main": [
        [
          {
            "node": "Daten aggregieren",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Daten aggregieren": {
      "main": [
        [
          {
            "node": "KI-Zusammenfassung generieren",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Ollama Model": {
      "ai_languageModel": [
        [
          {
            "node": "KI-Zusammenfassung generieren",
            "type": "ai_languageModel",
            "index": 0
          }
        ]
      ]
    },
    "KI-Zusammenfassung generieren": {
