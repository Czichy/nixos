# üîÑ n8n-Integrationsanalyse ‚Äì Edu-Search, Ollama & bestehende MicroVMs

## Workflow-Automation-Bewertung f√ºr die gesamte Infrastruktur

> **Ziel:** Bewertung, ob und wie n8n (HL-3-RZ-N8N-01) sinnvoll mit Edu-Search, Ollama und den
> bestehenden aktiven MicroVMs integriert werden kann. F√ºr jede Integration werden konkrete
> Anwendungsbeispiele aufgezeigt.

> **Stand:** Analyse basierend auf aktuellem Repo-Stand. n8n l√§uft bereits als MicroVM auf
> HOST-01 mit Anthropic Claude API-Key und Restic-Backup.

---

## Inhaltsverzeichnis

1. [Infrastruktur-√úbersicht](#1-infrastruktur-√ºbersicht)
2. [n8n ‚Üî Ollama: KI-Orchestrierung (H√∂chste Synergie)](#2-n8n--ollama-ki-orchestrierung-h√∂chste-synergie)
3. [n8n ‚Üî Edu-Search: Detailanalyse](#3-n8n--edu-search-detailanalyse)
4. [n8n ‚Üî Aktive MicroVMs: Integrationsbewertung](#4-n8n--aktive-microvms-integrationsbewertung)
5. [Priorisierte Umsetzungsreihenfolge](#5-priorisierte-umsetzungsreihenfolge)
6. [Technische Voraussetzungen](#6-technische-voraussetzungen)
7. [Offene Fragen & Risiken](#7-offene-fragen--risiken)
8. [Fazit](#8-fazit)

---

## 1. Infrastruktur-√úbersicht

### Aktive MicroVMs nach Host

| Host | MicroVM | Hostname | Funktion | Kategorie |
|---|---|---|---|---|
| **HOST-01** | samba | HL-3-RZ-SMB-01 | NAS/Dateifreigaben | Storage |
| | ente | HL-3-RZ-ENTE-01 | Foto-Speicher (Google-Photos-Alternative) | Media |
| | syncthing | HL-3-RZ-SYNC-01 | Dateisynchronisation (Christian) | Storage |
| | sync_ina | HL-3-RZ-SYNC-02 | Dateisynchronisation (Ina) | Storage |
| | influxdb | HL-3-RZ-INFLUX-01 | Zeitseriendatenbank | Monitoring |
| | forgejo | HL-3-RZ-GIT-01 | Git-Hosting | Development |
| | ibkr-flex | HL-3-RZ-IBKR-01 | IBKR Flex Report Downloader | Finance |
| | ib-gateway | HL-3-RZ-IBGW-01 | Interactive Brokers API Gateway | Finance |
| | parseable | HL-3-RZ-LOG-01 | Log-Management | Monitoring |
| | s3 | HL-3-RZ-S3-01 | S3-kompatibler Objektspeicher (Garage) | Storage |
| | grafana | HL-3-RZ-GRAFANA-01 | Dashboards & Alerting | Monitoring |
| | victoria | HL-3-RZ-METRICS-01 | VictoriaMetrics (Metriken) | Monitoring |
| | **n8n** | **HL-3-RZ-N8N-01** | **Workflow Automation** | **Automation** |
| | **edu-search** | **HL-3-RZ-EDU-01** | **Unterrichtsmaterial-Suche** | **Documents** |
| | paperless | HL-3-RZ-PAPERLESS-01 | Dokumentenmanagement (OCR, Tagging) | Documents |
| **HOST-02** | adguardhome | HL-3-RZ-DNS-01 | DNS Ad-Blocker | Infrastructure |
| | caddy | HL-3-DMZ-PROXY-01 | Reverse Proxy (DMZ) | Infrastructure |
| | kanidm | HL-3-RZ-AUTH-01 | Identity Provider (SSO/OAuth2) | Infrastructure |
| | nginx | ‚Äì | Webserver / Reverse Proxy | Infrastructure |
| | vaultwarden | HL-3-RZ-VAULT-01 | Passwort-Manager | Security |
| **HOST-03** | hass | HL-3-RZ-HASS-01 | Home Assistant (Smart Home) | Home Automation |
| | homepage | HL-3-RZ-HOME-01 | Dashboard | Infrastructure |
| | mosquitto | HL-3-RZ-MQTT-01 | MQTT Broker | Home Automation |
| | node-red | HL-3-RZ-RED-01 | Visual Flow Programming (IoT) | Home Automation |
| | powermeter | HL-3-RZ-POWER-02 | Stromz√§hler-Auswertung | Home Automation |
| | unifi | HL-3-RZ-UNIFI-01 | UniFi Network Controller | Infrastructure |

### n8n ‚Äì Aktueller Stand

n8n l√§uft als MicroVM auf HOST-01 (vlan40, IP: 10.15.40.39) mit folgenden Ressourcen:

- **Domain:** `n8n.czichy.com`
- **Port:** 5678
- **Secrets:**
  - `n8n-encryption-key` (interne Verschl√ºsselung)
  - `n8n-anthropic-api-key` (Claude AI ‚Äì bereits konfiguriert!)
- **Backup:** Restic ‚Üí OneDrive NAS (t√§glich 03:00)
- **Reverse Proxy:** Caddy (HOST-02 intern + PAZ-PROXY-01 extern)
- **Webhook-URL:** `https://n8n.czichy.com/`
- **Persistenz:** `/var/lib/n8n` (via impermanence nach `/persist`)

### KI-Backends ‚Äì Aktueller Stand

| Backend | Status | Wo | Zugang von n8n | Kosten | Qualit√§t |
|---|---|---|---|---|---|
| **Ollama** (ai.nix MicroVM) | ‚ö†Ô∏è CPU-only, 16GB RAM, 20 vCPUs | MicroVM auf HOST-01 | ‚úÖ vlan40 | Gratis, lokal | ‚ö†Ô∏è Langsam ohne GPU |
| **Ollama** (geplant: nativ HOST-01) | üîú PLAN_EDU_SEARCH Phase 1 | Nativ auf HOST-01 (CUDA, GTX 1660 SUPER 6GB) | ‚úÖ `http://10.15.40.10:11434` | Gratis, lokal | ‚úÖ Schnell mit GPU |
| **Anthropic Claude** | ‚úÖ Aktiv | Cloud API | ‚úÖ API-Key in n8n konfiguriert | Bezahlt (per Token) | ‚úÖ Sehr hoch |

> **Kernaussage:** Sobald Ollama nativ auf HOST-01 mit GPU l√§uft (PLAN_EDU_SEARCH Phase 1),
> wird n8n zum **zentralen KI-Orchestrator** mit zwei komplement√§ren Backends:
> - **Ollama** (lokal, gratis, GPU-beschleunigt, privat) ‚Üí Bulk-Aufgaben, on-premise Daten
> - **Claude** (Cloud, bezahlt, h√∂chste Qualit√§t) ‚Üí Komplexe Analysen, Fallback

---

## 2. n8n ‚Üî Ollama: KI-Orchestrierung (H√∂chste Synergie)

### ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê ‚Äì St√§rkster Integrationspunkt der gesamten Infrastruktur

### 2.1 Warum Ollama + n8n ein Game-Changer ist

n8n hat **native Nodes** f√ºr beide KI-Backends:

| n8n-Node | Backend | Funktion |
|---|---|---|
| **Ollama Chat Model** | Ollama (lokal) | Chat-Completion, Text-Generierung |
| **Ollama Embeddings** | Ollama (lokal) | Text-Embeddings f√ºr Vektor-Suche |
| **Anthropic Claude** | Claude (Cloud) | Chat-Completion, komplexe Analyse |
| **AI Agent** | Beide | LangChain-Agent mit Tools, kann zwischen Modellen w√§hlen |
| **Text Classifier** | Beide | Automatische Textklassifikation |
| **Summarizer** | Beide | Textzusammenfassung |
| **Sentiment Analysis** | Beide | Stimmungsanalyse |

### 2.2 KI-Strategie: "Ollama first, Claude fallback"

```text
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    n8n KI-Entscheidungslogik                        ‚îÇ
‚îÇ                                                                     ‚îÇ
‚îÇ  Aufgabe eingehend                                                  ‚îÇ
‚îÇ       ‚îÇ                                                             ‚îÇ
‚îÇ       ‚ñº                                                             ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    JA     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ
‚îÇ  ‚îÇ Private      ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫‚îÇ Ollama (lokal, GPU, gratis)      ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ Daten?       ‚îÇ          ‚îÇ mistral:7b / llama3.1:8b         ‚îÇ    ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò          ‚îÇ ‚Üí Rechnungen, Dokumente, Logs    ‚îÇ    ‚îÇ
‚îÇ         ‚îÇ NEIN             ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ
‚îÇ         ‚ñº                                                          ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    JA     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ
‚îÇ  ‚îÇ Bulk/        ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫‚îÇ Ollama (lokal, GPU, gratis)      ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ Repetitiv?   ‚îÇ          ‚îÇ ‚Üí Klassifikation, Tagging,       ‚îÇ    ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò          ‚îÇ   t√§gliche Reports               ‚îÇ    ‚îÇ
‚îÇ         ‚îÇ NEIN             ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ
‚îÇ         ‚ñº                                                          ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    JA     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ
‚îÇ  ‚îÇ Komplex /    ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫‚îÇ Anthropic Claude (Cloud, bezahlt)‚îÇ    ‚îÇ
‚îÇ  ‚îÇ Hohe         ‚îÇ          ‚îÇ ‚Üí Portfolio-Analyse, komplexe    ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ Qualit√§t?    ‚îÇ          ‚îÇ   Zusammenfassungen, Debugging   ‚îÇ    ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò          ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ
‚îÇ         ‚îÇ NEIN                                                     ‚îÇ
‚îÇ         ‚ñº                                                          ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îÇ
‚îÇ  ‚îÇ Ollama (Default ‚Äì spart Kosten, schnell, lokal)          ‚îÇ      ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### 2.3 Voraussetzungen

Ollama muss nativ auf HOST-01 laufen (PLAN_EDU_SEARCH Phase 1):

```nix
# hosts/HL-1-MRZ-HOST-01/modules/ollama.nix (geplant)
services.ollama = {
  enable = true;
  host = "0.0.0.0";       # Erreichbar f√ºr alle VMs in vlan40
  port = 11434;
  acceleration = "cuda";   # GPU-Beschleunigung via NVIDIA CUDA
};
# Firewall: Ollama nur aus vlan40 (Server-VLAN) erreichbar
networking.firewall.allowedTCPPorts = [ 11434 ];
```

n8n-Konfiguration (Credential in n8n-UI):
- **Ollama URL:** `http://10.15.40.10:11434`
- **Kein API-Key n√∂tig** (Ollama hat keine Auth, Firewall sch√ºtzt)
- **Modell:** `mistral:7b` (Standard) oder `llama3.1:8b` (Alternative)

### 2.4 Konkrete Workflows: Ollama + n8n

#### Workflow A: KI-gest√ºtzte Dokumenten-Klassifikation f√ºr Paperless-ngx

```text
Trigger: Paperless Webhook (neues Dokument verarbeitet)
  ‚îÇ
  ‚ñº
HTTP Request ‚Üí Paperless API: GET /api/documents/{id}/
  ‚Üí Extrahierter OCR-Text
  ‚îÇ
  ‚ñº
Ollama Chat Node (mistral:7b auf HOST-01:11434):
  Prompt: "Klassifiziere dieses Dokument. Antwort als JSON:
    {kategorie, korrespondent, dokumenttyp, datum, betrag_falls_rechnung}"
  ‚îÇ
  ‚ñº
Code Node: JSON parsen + Validierung
  ‚îÇ
  ‚ñº
Paperless API: PATCH /api/documents/{id}/
  ‚Üí Tags + Korrespondent automatisch setzen
  ‚îÇ
  ‚ñº
IF betrag > 500‚Ç¨ ‚Üí ntfy: "üí∞ Rechnung √ºber ‚Ç¨823 von Stadtwerke eingegangen"
```

**Vorteil Ollama statt Claude:** Dokumente enthalten private Daten (Rechnungen, Vertr√§ge,
pers√∂nliche Briefe) ‚Üí bleiben komplett lokal auf HOST-01, kein Cloud-Upload.

#### Workflow B: Trading-Report-Analyse (Hybrid: Ollama + Claude)

```text
Trigger: Cron (t√§glich 22:30, nach US-Marktschluss)
  ‚îÇ
  ‚ñº
HTTP Request: IBKR Flex API ‚Üí XML-Report herunterladen
  ‚îÇ
  ‚ñº
Code Node: XML ‚Üí JSON (Positionen, P&L, Dividenden)
  ‚îÇ
  ‚ñº
Ollama Chat Node (lokal, schnell, gratis):
  "Fasse zusammen: Tages-P&L, Top 3 Gewinner, Top 3 Verlierer,
   Dividenden-Eing√§nge. Antwort als JSON."
  ‚îÇ
  ‚ñº
IF besondere Ereignisse (Dividende > 100‚Ç¨, Tagesverlust > 2%):
  ‚îÇ
  ‚îú‚îÄ‚îÄ JA ‚Üí Anthropic Claude Node (Cloud, tiefere Analyse):
  ‚îÇ        "Analysiere diese Portfolio-Entwicklung. Kontext:
  ‚îÇ         {marktdaten}. Gibt es Handlungsbedarf?
  ‚îÇ         Sollte ich Positionen anpassen?"
  ‚îÇ        ‚îÇ
  ‚îÇ        ‚ñº
  ‚îÇ       ntfy (Priority: high): Zusammenfassung + KI-Einsch√§tzung
  ‚îÇ
  ‚îî‚îÄ‚îÄ NEIN ‚Üí ntfy (Priority: low):
             "üìà Portfolio-Update: +0.8% heute, keine Auff√§lligkeiten"
```

**Hybrid-Vorteil:** Ollama f√ºr den t√§glichen Standardreport (gratis, ~0.5s mit GPU),
Claude nur bei Ausrei√üern (bessere Analyse, aber kostet ~$0.02 pro Aufruf).

#### Workflow C: Smart-Home KI-Entscheidungen (Ollama, lokal)

```text
Trigger: Home Assistant Webhook (Energiepreis-Update alle 15min)
  ‚îÇ
  ‚ñº
HTTP Request: Tibber/aWATTar API ‚Üí Strompreise n√§chste 24h
  ‚îÇ
  ‚ñº
Ollama Chat Node (mistral:7b):
  "Gegeben diese Strompreise f√ºr die n√§chsten 24h: [...]
   Aktueller Batterie-SOC: 45%. Wallbox-Bedarf: 30kWh.
   Wann sollte die Wallbox laden? Wann Waschmaschine starten?
   Antwort als JSON: {wallbox_start, wallbox_stop, waschmaschine_start}"
  ‚îÇ
  ‚ñº
Code Node: JSON validieren + Plausibilit√§tspr√ºfung
  ‚îÇ
  ‚ñº
Home Assistant API: POST /api/services/automation/trigger
  ‚Üí Wallbox-Ladeplan setzen, Waschmaschinen-Timer
  ‚îÇ
  ‚ñº
InfluxDB: Logge Preis + Schaltaktion als Zeitreihe
  ‚îÇ
  ‚ñº
ntfy: "üîå Wallbox l√§dt 02:00-05:00 (g√ºnstigster Strom: 12ct/kWh)"
```

**Vorteil Ollama:** Kein Cloud-Roundtrip, schnell (~0.3s mit GPU), privat,
keine Kosten pro Abfrage. Energiedaten bleiben lokal.

#### Workflow D: Edu-Search ‚Äì KI-generierte Quizfragen aus indexiertem Material

```text
Trigger: Manuell (Webhook) oder Cron (Sonntag 18:00, Vorbereitung Woche)
  ‚îÇ
  ‚ñº
PostgreSQL Node (edu-search DB, READ-ONLY):
  SELECT extracted_text, fach, klasse, thema
  FROM documents
  WHERE fach = 'Englisch' AND klasse = '10' AND thema LIKE '%Macbeth%'
  LIMIT 3
  ‚îÇ
  ‚ñº
Ollama Chat Node (mistral:7b):
  "Du bist eine erfahrene Englischlehrerin. Erstelle 5 Multiple-Choice-Fragen
   zu diesem Unterrichtstext auf Niveau B2. Format als JSON:
   [{frage, optionen: [a,b,c,d], richtig: 'b', erklaerung}]"
  ‚îÇ
  ‚ñº
Code Node: JSON parsen + als HTML/Markdown formatieren
  ‚îÇ
  ‚ñº
E-Mail an Ina: "Hier sind 5 Quizfragen zu Macbeth f√ºr Klasse 10 (B2)"
```

**Mega-Mehrwert f√ºr Ina:** Aus den bereits indexierten und klassifizierten Materialien
automatisch √úbungsaufgaben, Vokabeltests oder Zusammenfassungen generieren ‚Äì ohne
dass Ina selbst mit KI interagieren muss.

#### Workflow E: Intelligente Log-Analyse bei Alerts (Ollama)

```text
Trigger: Grafana Alert Webhook ("Service X ungesund")
  ‚îÇ
  ‚ñº
HTTP Request: Parseable API ‚Üí Letzte 100 Log-Zeilen von Service X
  ‚îÇ
  ‚ñº
Ollama Chat Node (mistral:7b):
  "Analysiere diese Server-Log-Zeilen. Was ist die wahrscheinliche
   Ursache des Problems? Schlage einen konkreten Fix vor.
   Antwort als JSON: {ursache, schweregrad, fix_vorschlag}"
  ‚îÇ
  ‚ñº
IF schweregrad == "kritisch":
  ‚îÇ
  ‚îú‚îÄ‚îÄ JA ‚Üí ntfy (Priority: urgent):
  ‚îÇ        "üî¥ Grafana-Alert: PostgreSQL Connection Pool ersch√∂pft.
  ‚îÇ         Fix: max_connections in postgresql.conf erh√∂hen."
  ‚îÇ
  ‚îî‚îÄ‚îÄ NEIN ‚Üí ntfy (Priority: low):
             "üü° Grafana-Alert: Minor issue, vermutlich selbstheilend."
```

**Vorteil:** Statt nur "Service X is down" bekommt Christian eine KI-gest√ºtzte
Erstanalyse mit konkretem L√∂sungsvorschlag ‚Äì spart Debugging-Zeit.

#### Workflow F: W√∂chentliche KI-Zusammenfassung aller Systeme

```text
Trigger: Cron (Sonntag 21:00)
  ‚îÇ
  ‚ñº
Parallel Queries:
  ‚îå‚îÄ Grafana API: Alert-Historie der Woche
  ‚îú‚îÄ VictoriaMetrics: CPU/RAM/Disk-Trends aller Hosts
  ‚îú‚îÄ Parseable: Error-Count pro Service
  ‚îú‚îÄ Paperless: Neue Dokumente der Woche
  ‚îú‚îÄ Edu-Search DB: Neue Materialien + Fehlerrate
  ‚îî‚îÄ IBKR: Wochen-P&L
  ‚îÇ
  ‚ñº
Code Node: Alle Daten zu einem Kontext-String aggregieren
  ‚îÇ
  ‚ñº
Ollama Chat Node (mistral:7b):
  "Du bist ein System-Administrator. Fasse diese Wochendaten zusammen.
   Hebe Probleme hervor, schlage Optimierungen vor. Maximal 200 W√∂rter."
  ‚îÇ
  ‚ñº
ntfy/E-Mail an Christian:
  "üìã Wochenreport KW 23:
   ‚Ä¢ Infrastruktur: 2 Alerts (beide selbstheilend), Disk HOST-01 bei 72%
   ‚Ä¢ Dokumente: 12 neue in Paperless, 28 in Edu-Search indexiert
   ‚Ä¢ Portfolio: +1.8% Woche, ‚Ç¨45 Dividenden
   ‚Ä¢ Empfehlung: ZFS Scrub auf HOST-01 planen (letzter vor 45 Tagen)"
```

### 2.5 Zusammenfassung: Ollama + n8n

| Aspekt | Bewertung |
|---|---|
| **Synergie** | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê ‚Äì H√∂chste Priorit√§t in der gesamten Infrastruktur |
| **Voraussetzung** | Ollama muss auf HOST-01 nativ laufen (PLAN_EDU_SEARCH Phase 1) |
| **Netzwerk** | ‚úÖ Beide in vlan40, kein Firewall-Aufwand |
| **n8n-Support** | ‚úÖ Nativer Ollama Chat Node + Embeddings Node vorhanden |
| **Kosten** | Gratis (lokal), Claude nur als Fallback f√ºr ~$0.02/Aufruf |
| **Privatsph√§re** | ‚úÖ Alle Daten bleiben on-premise |
| **Aufwand Setup** | ~10 Minuten: Ollama-URL als Credential in n8n-UI hinterlegen |
| **GPU-Performance** | GTX 1660 SUPER: ~20-30 Tokens/s mit mistral:7b (ausreichend f√ºr Workflows) |

---

## 3. n8n ‚Üî Edu-Search: Detailanalyse

### 3.1 Aktueller Edu-Search-Aufbau (ohne n8n)

Die Edu-Search-Pipeline ist als **monolithischer Python-Daemon** (`indexer.py`) implementiert:

```text
Watchdog (PollingObserver, alle 60s)
    ‚îÇ virtiofs (inotify unzuverl√§ssig ‚Üí Polling)
    ‚ñº
Apache Tika (:9998, MicroVM-intern)
    ‚îÇ PUT /tika ‚Üí extrahierter Klartext
    ‚ñº
Ollama auf HOST-01 (:11434, nativ, GPU)
    ‚îÇ POST /api/generate ‚Üí JSON-Klassifikation
    ‚îÇ (Fach, Klasse, Thema, Typ, Niveau)
    ‚ñº
PostgreSQL (:5432, MicroVM-intern)
    ‚îÇ INSERT/UPDATE documents
    ‚ñº
MeiliSearch (:7700, MicroVM-intern)
    ‚îÇ POST /indexes/edu_documents/documents
    ‚ñº
Web-UI f√ºr Ina (Nginx :8080)
```

Der Indexer bietet:

- SHA256-basiertes Hash-Caching (keine Re-Verarbeitung unver√§nderter Dateien)
- PostgreSQL-Transaktionen mit Rollback bei Fehlern
- MeiliSearch-Index-Konfiguration (filterbare Felder, Ranking, Typo-Toleranz)
- Strukturierter Ollama-Prompt mit JSON-Parsing und Fehlerbehandlung
- systemd-Integration (Restart, Readiness-Checks, OOM-Score, Sicherheitsh√§rtung)
- Re-Indexierung als Oneshot-Service (`edu-reindex.service`)
- Graceful Shutdown mit Signal-Handling
- DB-Reconnect bei Verbindungsverlust

### 3.2 n8n als ERSATZ f√ºr die Core-Pipeline ‚Üí ‚ùå Nicht empfohlen

| Aspekt | Python-Indexer (Status quo) | n8n als Pipeline-Ersatz |
|---|---|---|
| **Dateisystem-Polling** | ‚úÖ PollingObserver f√ºr virtiofs nativ | ‚ùå Kein nativer virtiofs-Watcher; Cron m√∂glich, aber kein echtes Watching |
| **Hash-basiertes Caching** | ‚úÖ SHA256 pro Datei, √ºberspringt Unver√§nderte | ‚ö†Ô∏è Manuell nachzubauen, fehleranf√§llig in n8n-Expressions |
| **Tika-Integration** | ‚úÖ Direkte HTTP-Calls, Fehlerbehandlung, Timeout | ‚ö†Ô∏è HTTP-Request-Node m√∂glich, aber weniger robuste Fehlerbehandlung |
| **Ollama-Prompt** | ‚úÖ Prompt im Code, versioniert via Git | ‚ö†Ô∏è Prompt in n8n-UI; Versionierung nur √ºber n8n-Backup |
| **PostgreSQL** | ‚úÖ `psycopg2` mit Transaktionen + Rollback | ‚ö†Ô∏è n8n-PostgreSQL-Node: kein Transaktions-Support |
| **MeiliSearch** | ‚úÖ Nativer Python-Client, Index-Settings | ‚ùå Kein MeiliSearch-Node; nur generische HTTP-Requests |
| **Netzwerk-Isolierung** | ‚úÖ Alles MicroVM-intern (127.0.0.1) | ‚ùå n8n m√ºsste Cross-VM auf PG/Meili/Tika zugreifen |
| **Debugging** | ‚úÖ journald + `SyslogIdentifier` | ‚ö†Ô∏è n8n-UI-Debugging; kein journald |
| **Wartung** | ‚úÖ Nix-deklarativ, reproduzierbar | ‚ö†Ô∏è n8n-Workflows sind Zustand in `/var/lib/n8n` |
| **Performance** | ‚úÖ Effizient, minimaler Overhead | ‚ùå Node-Execution-Overhead pro Datei √ó tausende Dateien |
| **Batch-Verarbeitung** | ‚úÖ Iteriert √ºber alle Dateien in einem Prozess | ‚ö†Ô∏è n8n: jede Datei = separate Workflow-Execution |

**Fazit:** Der Python-Indexer ist hochspezialisiert f√ºr genau diesen Use Case. Eine Migration
nach n8n w√ºrde Komplexit√§t hinzuf√ºgen, die Netzwerk-Isolierung aufbrechen und Robustheit
einb√º√üen ‚Äì ohne echten Mehrwert. **Die Core-Pipeline bleibt im Python-Indexer.**

### 3.3 n8n als ERG√ÑNZUNG f√ºr Edu-Search ‚Üí ‚úÖ Empfohlen (selektiv)

n8n ist **nicht** als Ersatz geeignet, aber als **Orchestrator f√ºr Nebenaufgaben** wertvoll.
Diese Workflows greifen nur lesend auf die PostgreSQL-Datenbank der Edu-Search-MicroVM zu
und ben√∂tigen keine Modifikation der Core-Pipeline.

#### Workflow 1: T√§gliche Benachrichtigung √ºber neu indexierte Materialien

```text
Trigger: Cron (t√§glich 18:00, wenn Ina nach Hause kommt)
  ‚îÇ
  ‚ñº
PostgreSQL-Node (edu-search DB, READ-ONLY):
  SELECT filename, fach, klasse, thema, typ
  FROM documents
  WHERE indexed_at > NOW() - INTERVAL '24 hours'
    AND classification_status = 'success'
  ORDER BY fach, klasse
  ‚îÇ
  ‚ñº
IF-Node: Anzahl Ergebnisse > 0?
  ‚îÇ
  ‚îú‚îÄ‚îÄ JA ‚Üí Code-Node: Formatiere als Markdown-Liste
  ‚îÇ         ‚îÇ
  ‚îÇ         ‚ñº
  ‚îÇ        ntfy/E-Mail: "üìö 3 neue Materialien indexiert:
  ‚îÇ         ‚Ä¢ Macbeth_Arbeitsblatt.docx (Englisch, Klasse 10, B2)
  ‚îÇ         ‚Ä¢ Vocabulario_B1.pptx (Spanisch, Klasse 8, B1)
  ‚îÇ         ‚Ä¢ Grammar_Test.pdf (Englisch, Klasse 7, A2)"
  ‚îÇ
  ‚îî‚îÄ‚îÄ NEIN ‚Üí Nichts tun (kein Spam bei leeren Tagen)
```

**Aufwand:** ~30 Min | **Nutzen:** Ina wei√ü sofort, wenn neue Materialien verf√ºgbar sind

#### Workflow 2: W√∂chentlicher Status-Report

```text
Trigger: Cron (Sonntag 20:00)
  ‚îÇ
  ‚ñº
PostgreSQL-Node (3 Queries parallel):
  ‚îå‚îÄ Q1: SELECT fach, COUNT(*) FROM documents GROUP BY fach
  ‚îú‚îÄ Q2: SELECT classification_status, COUNT(*) FROM documents GROUP BY ...
  ‚îî‚îÄ Q3: SELECT COUNT(*) FROM documents WHERE indexed_at > NOW() - INTERVAL '7 days'
  ‚îÇ
  ‚ñº
Code-Node: Aggregiere zu Report
  ‚îÇ
  ‚ñº
ntfy an Christian:
  "üìä Edu-Search Wochenreport:
   247 Englisch | 183 Spanisch | 34 Sonstige
   12 fehlgeschlagen (Ollama-Timeout)
   +28 diese Woche neu indexiert"
```

**Aufwand:** ~20 Min | **Nutzen:** √úberblick √ºber System-Gesundheit und Wachstum

#### Workflow 3: Fehler-Eskalation bei Pipeline-Problemen

```text
Trigger: Cron (alle 6 Stunden)
  ‚îÇ
  ‚ñº
PostgreSQL-Node:
  SELECT COUNT(*) as failed FROM documents
  WHERE classification_status = 'failed'
    AND indexed_at > NOW() - INTERVAL '24 hours'
  ‚îÇ
  ‚ñº
IF-Node: failed > 10?
  ‚îÇ
  ‚îú‚îÄ‚îÄ JA ‚Üí ntfy (Priority: urgent):
  ‚îÇ        "‚ö†Ô∏è Edu-Search: 15 Dateien in 24h fehlgeschlagen! Ollama/Tika pr√ºfen!"
  ‚îÇ
  ‚îî‚îÄ‚îÄ NEIN ‚Üí Nichts tun
```

**Aufwand:** ~15 Min | **Nutzen:** Proaktive Fehlererkennung ohne manuelles Log-Lesen

#### Workflow 4: Re-Indexierung ausl√∂sen (manuell via Webhook)

```text
Trigger: n8n Webhook (manuell aus n8n-UI klickbar)
  ‚îÇ
  ‚ñº
SSH-Command-Node an HL-3-RZ-EDU-01:
  "systemctl start edu-reindex.service"
  ‚îÇ
  ‚ñº
Wait-Node: 10 Minuten
  ‚îÇ
  ‚ñº
PostgreSQL-Node:
  SELECT COUNT(*) FROM documents WHERE classification_status = 'success'
  ‚îÇ
  ‚ñº
ntfy: "‚úÖ Re-Index abgeschlossen: 430 Dateien erfolgreich klassifiziert"
```

**Aufwand:** ~25 Min | **Nutzen:** Bequemer Trigger nach Ollama-Modellwechsel oder Prompt-√Ñnderung

> **Hinweis:** Workflow D aus Abschnitt 2.4 (KI-generierte Quizfragen) ist ebenfalls ein
> Edu-Search-Workflow, nutzt aber prim√§r die Ollama-Integration und steht daher dort.

### 3.4 Voraussetzungen f√ºr n8n ‚Üí Edu-Search-Anbindung

n8n (HL-3-RZ-N8N-01, 10.15.40.39) muss auf PostgreSQL der Edu-Search-MicroVM zugreifen:

1. **Firewall in `edu-search.nix`:** Port 5432 f√ºr n8n-IP freigeben
2. **PostgreSQL `listen_addresses`:** Von `127.0.0.1` auf `127.0.0.1,10.15.40.114` erweitern
3. **PostgreSQL-User:** Read-only User `n8n_reader` mit `SELECT`-Rechten auf `documents`
4. **pg_hba.conf:** `host edu_search n8n_reader 10.15.40.39/32 md5`

```nix
# In edu-search/postgresql.nix erg√§nzen:
services.postgresql.settings.listen_addresses = lib.mkForce "127.0.0.1";
# n8n-Zugriff wird √ºber pg_hba geregelt ‚Äì listen bleibt intern,
# n8n greift √ºber die MicroVM-IP zu (10.15.40.114:5432)
services.postgresql.authentication = lib.mkAfter ''
  host edu_search n8n_reader 10.15.40.39/32 md5
'';
```

---

## 4. n8n ‚Üî Aktive MicroVMs: Integrationsbewertung

### Bewertungs√ºbersicht

| MicroVM | Synergie | Begr√ºndung | Top-Use-Case |
|---|---|---|---|
| **Ollama (HOST-01 nativ)** | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | Zentrales KI-Backend f√ºr alle Workflows | KI-Orchestrator (siehe Abschnitt 2) |
| **Paperless-ngx** | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | REST-API + Ollama = KI-Auto-Tagging | Dokumenten-Klassifikation (Workflow A) |
| **IBKR Flex / IB Gateway** | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | Ersetzt Shell-Skript, erm√∂glicht KI-Analyse | Portfolio-Report (Workflow B) |
| **Home Assistant** | ‚≠ê‚≠ê‚≠ê‚≠ê | Komplexe Automationen jenseits HA-M√∂glichkeiten | Strompreis-Optimierung (Workflow C) |
| **Edu-Search** | ‚≠ê‚≠ê‚≠ê‚≠ê | Erg√§nzung (nicht Ersatz!) der Core-Pipeline | Benachrichtigungen + Quizfragen (Workflows 1-4, D) |
| **Grafana + Parseable** | ‚≠ê‚≠ê‚≠ê | Alert-Eskalation mit KI-Analyse | Log-Analyse (Workflow E) |
| **Forgejo** | ‚≠ê‚≠ê‚≠ê | Webhook-basierte CI/CD-Orchestrierung | Deployment-Notifications, Auto-Issues |
| **VictoriaMetrics + InfluxDB** | ‚≠ê‚≠ê‚≠ê | Metrik-Aggregation + KI-Trend-Analyse | Wochenreport (Workflow F) |
| **Linkwarden** | ‚≠ê‚≠ê | Auto-Import + Kategorisierung | Bookmark-Auto-Tagging |
| **Samba / Syncthing** | ‚≠ê‚≠ê | Datei√§nderungs-Notifications | Speicherplatz-Monitoring |
| **Node-RED** | ‚≠ê‚≠ê | √úberlappende F√§higkeiten (IoT bleibt bei Node-RED) | Br√ºcke f√ºr nicht-IoT-Workflows |
| **Mosquitto** | ‚≠ê‚≠ê | n8n hat MQTT-Node, aber Node-RED ist besser daf√ºr | MQTT‚ÜíHTTP-Br√ºcke f√ºr externe APIs |
| **AdGuard Home** | ‚≠ê | Wenig Automatisierungsbedarf | DNS-Statistik-Reports |
| **Ente Photos** | ‚≠ê | Limitierte API | Speicherplatz-Alerts |
| **Vaultwarden** | ‚≠ê | Sicherheitskritisch, sollte nicht automatisiert werden | Keine Empfehlung |
| **Kanidm** | ‚≠ê | SSO-Infrastruktur, nicht automatisierbar | Keine Empfehlung |
| **S3 (Garage)** | ‚≠ê | Backend-Storage, kein Frontend-Use-Case | Bucket-Statistiken |
| **Homepage** | ‚≠ê | Statisches Dashboard | Keine Empfehlung |
| **UniFi** | ‚≠ê | UniFi hat eigene Automatisierung | Netzwerk-Alerts (optional) |
| **Powermeter** | ‚≠ê‚≠ê | Daten √ºber HA/InfluxDB erreichbar | Stromverbrauchs-Anomalien |

### 4.1 Paperless-ngx ‚Üí ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê (H√∂chste Synergie neben Ollama)

Paperless hat eine vollst√§ndige REST-API und verarbeitet bereits OCR-Text.
n8n + Ollama k√∂nnen das Tagging revolutionieren.

**Bereits vorhanden:** Paperless OAuth2 via Kanidm, Webhook-Support, REST-API.

```text
Workflow: "KI-Auto-Tagging f√ºr neue Dokumente"
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
Trigger: Paperless Webhook (neues Dokument fertig verarbeitet)
  ‚îÇ
  ‚ñº
HTTP Request: Paperless API ‚Üí GET /api/documents/{id}/
  ‚Üí OCR-Text + aktuelle Tags
  ‚îÇ
  ‚ñº
Ollama Chat Node (mistral:7b, lokal):
  "Analysiere dieses Dokument. Bestimme:
   1. Kategorie: Rechnung/Vertrag/Brief/Beh√∂rde/Versicherung/Steuer/Sonstiges
   2. Korrespondent: Wer hat das geschrieben?
   3. Betrag (falls Rechnung): in EUR
   4. F√§lligkeitsdatum (falls vorhanden)
   Antwort als JSON."
  ‚îÇ
  ‚ñº
HTTP Request: Paperless API ‚Üí PATCH /api/documents/{id}/
  ‚Üí Tags setzen, Korrespondent zuweisen
  ‚îÇ
  ‚ñº
IF Kategorie == "Rechnung" AND Betrag > 200:
  ‚Üí ntfy: "üí∞ Neue Rechnung: ‚Ç¨823 von Stadtwerke, f√§llig am 15.07."
```

**Voraussetzungen:**
- Paperless API-Token als n8n-Credential
- Paperless Webhook-URL konfigurieren (POST an `https://n8n.czichy.com/webhook/paperless`)
- Ollama erreichbar (HOST-01:11434)

### 4.2 IBKR Flex / IB Gateway ‚Üí ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê

Der aktuelle `ibkr-flex.nix` ist ein einfaches Shell-Skript mit Cron-Timer.
n8n kann das komplett ersetzen und um KI-Analyse erweitern.

**Aktuell (`ibkr-flex.nix`):** Shell-Skript ‚Üí Download XML ‚Üí Sortiere in Ordner ‚Üí Healthcheck-Ping

**Mit n8n:**

```text
Workflow: "IBKR Flex Download + KI-Analyse + Metriken"
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
Trigger: Cron (t√§glich 22:30)
  ‚îÇ
  ‚ñº
HTTP Request: IBKR Flex API
  ‚Üí Token aus n8n-Credential (kein age-Secret n√∂tig)
  ‚Üí XML-Report herunterladen
  ‚îÇ
  ‚ñº
Code Node: XML ‚Üí JSON
  ‚Üí Positionen, Tages-P&L, Dividenden, Trades extrahieren
  ‚îÇ
  ‚ñº
Parallel:
  ‚îå‚îÄ HTTP Request: VictoriaMetrics API
  ‚îÇ    ‚Üí NAV, Cash, Margin als Zeitreihe schreiben
  ‚îÇ    ‚Üí In Grafana als Dashboard sichtbar
  ‚îÇ
  ‚îú‚îÄ Ollama Chat Node: Tages-Zusammenfassung
  ‚îÇ    ‚Üí "Top Gewinner: MSFT +2.3%, Verlierer: TSLA -1.8%"
  ‚îÇ
  ‚îî‚îÄ IF Dividende eingegangen:
       ‚Üí InfluxDB: Dividende loggen
       ‚Üí ntfy: "üí∞ Dividende: $45 von AAPL"
  ‚îÇ
  ‚ñº
ntfy: "üìà Portfolio-Update: +0.8% ($1,234). NAV: $154,320"
```

**Voraussetzungen:**
- IBKR Flex Token als n8n-Credential
- VictoriaMetrics-Zugriff (schon in vlan40)
- Optional: ibkr-flex MicroVM kann langfristig entfallen

### 4.3 Home Assistant ‚Üí ‚≠ê‚≠ê‚≠ê‚≠ê

HA hat eine m√§chtige REST-API. n8n erg√§nzt HA dort, wo **externe APIs + KI-Logik** n√∂tig sind.
IoT-Basisautomationen bleiben in HA/Node-RED.

```text
Workflow: "Intelligente Anwesenheitserkennung + Energieoptimierung"
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
Trigger: HA Webhook (T√ºr-Sensor + Bewegungsmelder-Kombination)
  ‚îÇ
  ‚ñº
HTTP Request: HA API ‚Üí Aktueller Zustand aller Sensoren
  (T√ºr, Bewegungsmelder, Handy-GPS, Licht-Status)
  ‚îÇ
  ‚ñº
Ollama Chat Node:
  "Gegeben: T√ºr offen seit 5min, kein Bewegungsmelder aktiv,
   Handy-GPS > 500m, Lichter an. Ist jemand zuhause?
   Antwort: {zuhause: true/false, confidence: 0-100, aktion}"
  ‚îÇ
  ‚ñº
IF zuhause == false AND confidence > 80:
  ‚îÇ
  ‚ñº
HA API: POST /api/services/scene/turn_on
  ‚Üí Szene "Niemand zuhause" (Heizung runter, Lichter aus)
  ‚îÇ
  ‚ñº
ntfy: "üè† Automatisch auf Abwesenheits-Modus geschaltet"
```

**Abgrenzung zu Node-RED:** Node-RED bleibt f√ºr direkte IoT-Flows (MQTT, Zigbee, einfache
Automationen). n8n √ºbernimmt Flows, die KI, externe APIs oder Cross-Service-Logik brauchen.

### 4.4 Grafana + Parseable ‚Üí ‚≠ê‚≠ê‚≠ê

```text
Workflow: "Alert-Eskalation mit KI-Erstanalyse"
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
Trigger: Grafana Alert Webhook
  ‚îÇ
  ‚ñº
Code Node: Alert-Payload parsen (Service-Name, Metrik, Schwellwert)
  ‚îÇ
  ‚ñº
HTTP Request: Parseable API ‚Üí Letzte 100 Log-Zeilen des betroffenen Service
  ‚îÇ
  ‚ñº
Ollama Chat Node:
  "Analysiere diese Logs. Ursache? Schweregrad? Fix-Vorschlag?"
  ‚îÇ
  ‚ñº
Switch Node (nach Schweregrad):
  ‚îú‚îÄ‚îÄ kritisch ‚Üí ntfy (urgent) + Forgejo Issue erstellen
  ‚îú‚îÄ‚îÄ warnung  ‚Üí ntfy (normal)
  ‚îî‚îÄ‚îÄ info     ‚Üí Nur loggen, kein Alert
```

### 4.5 Forgejo ‚Üí ‚≠ê‚≠ê‚≠ê

```text
Workflow 1: "Auto-Issue bei Monitoring-Alert"
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
Trigger: Von Workflow 4.4 (Alert-Eskalation, Schweregrad "kritisch")
  ‚îÇ
  ‚ñº
Forgejo API: POST /api/v1/repos/christian/nixos/issues
  ‚Üí Title: "üî¥ Alert: {service} down seit {dauer}"
  ‚Üí Body: KI-Analyse + Log-Auszug + Fix-Vorschlag

Workflow 2: "Deployment-Notification"
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
Trigger: Forgejo Webhook (Push auf main-Branch)
  ‚îÇ
  ‚ñº
IF Commit-Message enth√§lt "[deploy]":
  ‚Üí ntfy: "üöÄ Neuer NixOS-Commit: {message}"
```

### 4.6 Linkwarden ‚Üí ‚≠ê‚≠ê

```text
Workflow: "Auto-Kategorisierung neuer Bookmarks"
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
Trigger: Cron (st√ºndlich) oder Linkwarden Webhook
  ‚îÇ
  ‚ñº
Linkwarden API: GET /api/v1/links?sort=-createdAt&take=10
  ‚Üí Neue unkategorisierte Bookmarks
  ‚îÇ
  ‚ñº
Ollama Chat Node: "Kategorisiere diese URLs:
  {url_1}: ..., {url_2}: ...
  Antwort als JSON: [{url, kategorie, tags}]"
  ‚îÇ
  ‚ñº
Linkwarden API: PUT ‚Üí Tags + Collection zuweisen
```

### 4.7 Node-RED / Mosquitto ‚Üí ‚≠ê‚≠ê

n8n und Node-RED haben √ºberlappende F√§higkeiten. Klare Abgrenzung:

| Bereich | Tool | Begr√ºndung |
|---|---|---|
| IoT-Automationen (MQTT, Zigbee) | **Node-RED** | Besser f√ºr Echtzeit-IoT, direkter MQTT-Support |
| Sensordaten-Verarbeitung | **Node-RED** | L√§uft auf HOST-03 nah an Mosquitto/HA |
| KI-gest√ºtzte Workflows | **n8n** | Native Ollama/Claude-Nodes |
| Cross-Service-Orchestrierung | **n8n** | Bessere API-Integration, Credentials-Management |
| Externe APIs (IBKR, Tibber, etc.) | **n8n** | HTTP-Request-Node + OAuth2-Support |
| Dashboard-Notifications | **n8n** | ntfy/E-Mail-Integration |

n8n kann optional als MQTT-Client an Mosquitto andocken (n8n hat einen MQTT-Trigger-Node),
um IoT-Events als Ausl√∂ser f√ºr KI-Workflows zu nutzen. Beispiel:

```text
Mosquitto (MQTT) ‚Üí n8n MQTT-Trigger ‚Üí Ollama ‚Üí ntfy
"Stromz√§hler meldet ungew√∂hnlich hohen Verbrauch um 3:00 nachts"
‚Üí KI: "Wahrscheinlich K√ºhlschrank-Kompressor defekt. Pr√ºfen!"
```

### 4.8 Samba / Syncthing ‚Üí ‚≠ê‚≠ê

```text
Workflow: "Speicherplatz-Monitoring + Auto-Warnung"
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
Trigger: Cron (t√§glich 08:00)
  ‚îÇ
  ‚ñº
SSH-Command an HOST-01: "zpool list -Hp storage"
  ‚Üí Verwendet, Frei, Fragmentierung
  ‚îÇ
  ‚ñº
IF Belegung > 85%:
  ‚îÇ
  ‚ñº
Ollama: "Analysiere diese ZFS-Pool-Statistiken. Welche Datasets
  wachsen am schnellsten? Wann ist der Pool voll (Prognose)?"
  ‚îÇ
  ‚ñº
ntfy (Priority: high):
  "üíæ Storage-Pool bei 87%! Prognose: voll in ~45 Tagen.
   Gr√∂√üte Datasets: immich (234GB), paperless (89GB)"
```

### 4.9 Niedrige Synergie (‚≠ê) ‚Äì Keine Empfehlung

| MicroVM | Warum nicht? |
|---|---|
| **Vaultwarden** | Sicherheitskritisch. Automatisierung = Angriffsfl√§che. Keine API-Calls durch n8n. |
| **Kanidm** | SSO-Infrastruktur. √Ñnderungen nur manuell/deklarativ via Nix. |
| **S3 (Garage)** | Backend-Storage ohne Frontend-Use-Case. Bucket-Statistiken √ºber Grafana abbildbar. |
| **Homepage** | Statisches Dashboard, keine Automatisierung n√∂tig. |
| **UniFi** | Hat eigene Automatisierung/Alerting. n8n-Integration w√§re Overhead. |
| **Ente Photos** | Sehr limitierte API, keine sinnvollen Automations-Trigger. |
| **AdGuard Home** | Funktioniert autonom. Maximal: DNS-Statistik-Report (kaum Mehrwert). |

---

## 5. Priorisierte Umsetzungsreihenfolge

### Phase 0: Voraussetzung (muss zuerst erledigt werden)

| # | Aufgabe | Abh√§ngigkeit | Aufwand |
|---|---|---|---|
| 0.1 | Ollama nativ auf HOST-01 mit GPU (PLAN_EDU_SEARCH Phase 1) | NVIDIA-Treiber + CUDA | 1 Wochenende |
| 0.2 | Ollama-Credential in n8n-UI anlegen (`http://10.15.40.10:11434`) | 0.1 | 5 Minuten |
| 0.3 | Anthropic-Credential in n8n-UI verifizieren (API-Key schon da) | ‚Äì | 5 Minuten |

### Phase 1: Quick Wins (sofort nach Ollama-Setup)

| # | Workflow | Synergie | Aufwand | Nutzen |
|---|---|---|---|---|
| 1.1 | W√∂chentliche KI-Zusammenfassung aller Systeme (Workflow F) | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ~45 Min | √úberblick √ºber gesamte Infrastruktur |
| 1.2 | IBKR Tages-Report mit KI-Zusammenfassung (Workflow B) | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ~60 Min | Ersetzt Shell-Skript, KI-Analyse gratis |
| 1.3 | Paperless KI-Auto-Tagging (Workflow A) | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ~45 Min | Automatisches Dokumenten-Tagging |

### Phase 2: Edu-Search-Erg√§nzungen (nach Edu-Search Go-Live)

| # | Workflow | Synergie | Aufwand | Nutzen |
|---|---|---|---|---|
| 2.1 | Edu-Search Benachrichtigungen f√ºr Ina (Workflow 1) | ‚≠ê‚≠ê‚≠ê‚≠ê | ~30 Min | Ina wird √ºber neue Materialien informiert |
| 2.2 | Edu-Search Wochenreport (Workflow 2) | ‚≠ê‚≠ê‚≠ê‚≠ê | ~20 Min | System-Gesundheit im Blick |
| 2.3 | Edu-Search Fehler-Eskalation (Workflow 3) | ‚≠ê‚≠ê‚≠ê‚≠ê | ~15 Min | Proaktive Fehlererkennung |
| 2.4 | KI-generierte Quizfragen (Workflow D) | ‚≠ê‚≠ê‚≠ê‚≠ê | ~60 Min | Mega-Mehrwert f√ºr Ina |

### Phase 3: Smart Home + Monitoring (optional, laufend)

| # | Workflow | Synergie | Aufwand | Nutzen |
|---|---|---|---|---|
| 3.1 | Smart-Home Strompreis-Optimierung (Workflow C) | ‚≠ê‚≠ê‚≠ê‚≠ê | ~60 Min | Energiekosten senken |
| 3.2 | Alert-Eskalation mit KI-Log-Analyse (Workflow E) | ‚≠ê‚≠ê‚≠ê | ~45 Min | Schnellere Problemdiagnose |
| 3.3 | Forgejo Auto-Issues bei Alerts | ‚≠ê‚≠ê‚≠ê | ~30 Min | Automatische Dokumentation |
| 3.4 | Speicherplatz-Monitoring (Workflow 4.8) | ‚≠ê‚≠ê | ~20 Min | Rechtzeitige Warnung |

### Gesamtaufwand-Sch√§tzung

| Phase | Aufwand | Zeitrahmen |
|---|---|---|
| Phase 0 | ~1 Wochenende | Vor allem anderen |
| Phase 1 | ~2.5 Stunden | 1 Abend nach Phase 0 |
| Phase 2 | ~2 Stunden | Nach Edu-Search Go-Live |
| Phase 3 | ~2.5 Stunden | Laufend, nach Bedarf |
| **Gesamt** | **~1 Wochenende + 7 Stunden** | **Verteilt √ºber 3-4 Wochen** |

---

## 6. Technische Voraussetzungen

### 6.1 Netzwerk (vlan40)

Alle relevanten Services liegen bereits in vlan40. n8n (10.15.40.39) kann erreichen:

| Ziel | IP | Port | Status |
|---|---|---|---|
| Ollama (HOST-01 nativ, geplant) | 10.15.40.10 | 11434 | üîú Nach PLAN_EDU_SEARCH Phase 1 |
| Edu-Search PostgreSQL | 10.15.40.114 | 5432 | ‚ö†Ô∏è Firewall + pg_hba anpassen |
| Paperless-ngx | 10.15.40.16 | 28981 | ‚úÖ Erreichbar |
| Grafana | 10.15.40.111 | 3000 | ‚úÖ Erreichbar |
| VictoriaMetrics | 10.15.40.112 | 8428 | ‚úÖ Erreichbar |
| InfluxDB | 10.15.40.12 | 8086 | ‚úÖ Erreichbar |
| Parseable | 10.15.40.18 | 8000 | ‚úÖ Erreichbar |
| Forgejo | 10.15.40.14 | 3000 | ‚úÖ Erreichbar |
| Home Assistant | 10.15.40.36 | 8123 | ‚úÖ Erreichbar |
| Linkwarden | 10.15.40.x | 3000 | ‚úÖ Erreichbar |
| Mosquitto (MQTT) | 10.15.40.33 | 1883 | ‚úÖ Erreichbar |

### 6.2 n8n-Credentials (in n8n-UI zu konfigurieren)

| Credential | Typ | Quelle |
|---|---|---|
| Ollama | URL: `http://10.15.40.10:11434` | Kein Auth n√∂tig (Firewall sch√ºtzt) |
| Anthropic Claude | API-Key | Bereits als `n8n-anthropic-api-key` Secret vorhanden |
| Paperless-ngx | API-Token | In Paperless-Admin generieren |
| Forgejo | API-Token | In Forgejo-Settings generieren |
| Home Assistant | Long-Lived Access Token | In HA-Profil generieren |
| PostgreSQL (edu-search) | Host/Port/User/Pass | Read-only User `n8n_reader` anlegen |
| IBKR Flex | Token + Query-ID | Aus bestehender `ibkr-flex.nix` Secret migrieren |
| ntfy | URL + Auth | `https://ntfy.czichy.com`, bestehende Credentials |
| VictoriaMetrics | URL | `http://10.15.40.112:8428`, kein Auth |

### 6.3 Nix-√Ñnderungen

Minimale √Ñnderungen an bestehenden MicroVMs f√ºr n8n-Zugriff:

```nix
# edu-search/postgresql.nix ‚Äì n8n Read-Only-Zugriff
services.postgresql.settings.listen_addresses = "127.0.0.1,10.15.40.114";
networking.firewall.allowedTCPPorts = [ 5432 ]; # F√ºr n8n
services.postgresql.authentication = lib.mkAfter ''
  host edu_search n8n_reader 10.15.40.39/32 md5
'';

# Optional: Paperless Webhook-URL in paperless settings
# services.paperless.settings.PAPERLESS_POST_CONSUME_SCRIPT = ...
# (Alternativ: Paperless-Webhook √ºber n8n-Community-Node)
```

### 6.4 ai.nix Refactoring nach Ollama-Migration

Sobald Ollama nativ auf HOST-01 l√§uft:

```nix
# ai.nix ‚Äì Reduzierte MicroVM: nur noch Open-WebUI
{
  microvm.mem = 1024 * 2;  # Statt 16GB nur noch 2GB f√ºr Open-WebUI
  microvm.vcpu = 2;         # Statt 20 nur noch 2

  # Ollama ENTFERNT ‚Äì l√§uft nativ auf HOST-01
  # services.ollama.enable = false;

  services.open-webui = {
    enable = true;
    environment = {
      # Zeigt auf nativen Ollama-Service auf HOST-01
      OLLAMA_BASE_URL = "http://10.15.40.10:11434";
    };
  };
}
# Ersparnis: ~14GB RAM, ~18 vCPUs
```

---

## 7. Offene Fragen & Risiken

### Offene Fragen

| # | Frage | Auswirkung | Priorit√§t |
|---|---|---|---|
| 1 | Soll die ai.nix MicroVM nach Ollama-Migration komplett entfernt oder f√ºr Open-WebUI behalten werden? | RAM-Planung HOST-01 | Mittel |
| 2 | Soll n8n langfristig die ibkr-flex MicroVM ersetzen (Shell-Skript ‚Üí n8n Workflow)? | Eine MicroVM weniger | Niedrig |
| 3 | Wie werden n8n-Workflows versioniert? Export als JSON ins Git-Repo? | Reproduzierbarkeit | Hoch |
| 4 | Rate-Limiting f√ºr Anthropic Claude API? Budget-Obergrenze pro Monat? | Kostenkontrolle | Mittel |
| 5 | Soll n8n Community-Nodes nutzen d√ºrfen (z.B. Paperless-Node)? | Sicherheit vs. Komfort | Niedrig |
| 6 | Ollama-Modellwahl: `mistral:7b` vs. `llama3.1:8b`? Beide passen in 6GB VRAM. | Qualit√§t der KI-Outputs | Mittel |

### Risiken

| Risiko | Schwere | Wahrscheinlichkeit | Mitigation |
|---|---|---|---|
| n8n wird Single Point of Failure f√ºr Automationen | Mittel | Niedrig | Core-Services (Edu-Search-Pipeline, HA-Automationen) sind unabh√§ngig von n8n. n8n ist nur Erg√§nzung. |
| Ollama-GPU-Konkurrenz zwischen Edu-Search-Indexer und n8n-Workflows | Mittel | Mittel | Ollama queued Requests automatisch. Bei Engpass: n8n-Workflows auf Off-Peak-Zeiten (nachts) legen. |
| Anthropic-API-Kosten steigen bei h√§ufiger Nutzung | Niedrig | Niedrig | "Ollama first"-Strategie: Claude nur als Fallback. Budget-Alert in n8n wenn > $10/Monat. |
| n8n-Workflows sind Zustand (nicht deklarativ wie Nix) | Mittel | Hoch | Regelm√§√üiger JSON-Export der Workflows ins Git-Repo. Restic-Backup bereits konfiguriert. |
| Sicherheitsl√ºcke durch n8n-Zugriff auf viele Services | Mittel | Niedrig | n8n nur in vlan40 (kein Internet-Zugriff au√üer Anthropic API). Credentials verschl√ºsselt mit `n8n-encryption-key`. Read-only DB-User wo m√∂glich. |
| GTX 1660 SUPER VRAM (6GB) reicht nicht f√ºr gr√∂√üere Modelle | Niedrig | Niedrig | mistral:7b (~4.1GB) und llama3.1:8b (~4.7GB) passen. F√ºr gr√∂√üere Modelle: Claude als Fallback. |

---

## 8. Fazit

### Kernaussagen

1. **Ollama + n8n ist der st√§rkste Integrationspunkt** der gesamten Infrastruktur (‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê).
   Sobald Ollama nativ auf HOST-01 mit GPU l√§uft, wird n8n zum zentralen KI-Orchestrator mit
   zwei komplement√§ren Backends (Ollama lokal + Claude Cloud).

2. **Edu-Search Core-Pipeline bleibt im Python-Indexer** (‚ùå kein n8n-Ersatz). Der spezialisierte
   Daemon mit virtiofs-Polling, Hash-Caching und PostgreSQL-Transaktionen ist n8n √ºberlegen.
   n8n erg√§nzt mit Benachrichtigungen, Reports und KI-generierten Quizfragen (‚úÖ).

3. **Paperless-ngx und IBKR Flex** profitieren am st√§rksten von n8n + Ollama (‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê):
   KI-Auto-Tagging f√ºr Dokumente (lokal, privat) und t√§gliche Portfolio-Analysen mit
   Hybrid-Strategie (Ollama Standard, Claude bei Ausrei√üern).

4. **Home Assistant** gewinnt KI-gest√ºtzte Entscheidungsf√§higkeit f√ºr Energieoptimierung
   und intelligente Anwesenheitserkennung ‚Äì ohne Cloud-Abh√§ngigkeit (‚≠ê‚≠ê‚≠ê‚≠ê).

5. **Gesamtaufwand:** ~1 Wochenende (Ollama-Setup) + ~7 Stunden (Workflows), verteilt √ºber
   3-4 Wochen. Der ROI ist hoch: automatische Dokumenten-Klassifikation, Portfolio-Reports
   und Quizfragen-Generierung f√ºr Ina allein rechtfertigen den Aufwand.

### N√§chster Schritt

‚Üí **PLAN_EDU_SEARCH Phase 1 umsetzen** (NVIDIA-Treiber + Ollama nativ auf HOST-01).
   Danach sofort Phase 1 Quick Wins (Abschnitt 5): Ollama-Credential in n8n anlegen,
   IBKR-Report und Paperless-Auto-Tagging als erste Workflows.