# üéì Edu-Search ‚Äì Implementierungsplan

## Unterrichtsmaterial-Suchsystem f√ºr Ina (Lehrerin Englisch/Spanisch)

> **Ziel:** Ina kann √ºber eine einfache Weboberfl√§che im Browser alle ihre Unterrichtsmaterialien
> durchsuchen ‚Äì nach Fach, Klasse, Thema, Typ und Freitext. Die Originaldateien auf dem NAS
> bleiben unver√§ndert. Das System indexiert automatisch bei √Ñnderungen.

---

## Inhaltsverzeichnis

1. [Architektur-√úbersicht](#1-architektur-√ºbersicht)
2. [Entscheidung: Ollama auf HOST-01 vs. MicroVM](#2-entscheidung-ollama-auf-host-01-vs-microvm)
3. [Komponenten-Details](#3-komponenten-details)
4. [Datei- und Verzeichnisstruktur im Nix-Repo](#4-datei--und-verzeichnisstruktur-im-nix-repo)
5. [Phase 1 ‚Äì Fundament](#5-phase-1--fundament-12-wochenenden)
6. [Phase 2 ‚Äì Suche & Indexierung](#6-phase-2--suche--indexierung-1-wochenende)
7. [Phase 3 ‚Äì Web-UI f√ºr Ina](#7-phase-3--web-ui-f√ºr-ina-1-wochenende)
8. [Phase 4 ‚Äì Backup & Monitoring](#8-phase-4--backup--monitoring)
9. [Netzwerk & Globals](#9-netzwerk--globals)
10. [Offene Fragen & Risiken](#10-offene-fragen--risiken)

---

## 1. Architektur-√úbersicht

```text
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                          HL-1-MRZ-HOST-01                                ‚îÇ
‚îÇ            (AMD Ryzen Matisse, 64GB RAM, GTX 1660 SUPER 6GB, ZFS)        ‚îÇ
‚îÇ                                                                          ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                       ‚îÇ
‚îÇ  ‚îÇ       Direkt auf HOST-01 (nativ)              ‚îÇ                       ‚îÇ
‚îÇ  ‚îÇ                                               ‚îÇ                       ‚îÇ
‚îÇ  ‚îÇ  ‚óè NVIDIA-Treiber + CUDA Toolkit              ‚îÇ                       ‚îÇ
‚îÇ  ‚îÇ  ‚óè Ollama Service (GPU-beschleunigt)          ‚îÇ                       ‚îÇ
‚îÇ  ‚îÇ    - Port 11434 (nur localhost + vlan40)       ‚îÇ                       ‚îÇ
‚îÇ  ‚îÇ    - Modell: mistral:7b oder llama3.1:8b      ‚îÇ                       ‚îÇ
‚îÇ  ‚îÇ  ‚óè Open-WebUI (optional, Port 11222)          ‚îÇ                       ‚îÇ
‚îÇ  ‚îÇ                                               ‚îÇ                       ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                       ‚îÇ
‚îÇ                            ‚îÇ HTTP :11434                                  ‚îÇ
‚îÇ                            ‚ñº                                             ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ  ‚îÇ              MicroVM: "edu-search"                                  ‚îÇ ‚îÇ
‚îÇ  ‚îÇ              (HL-3-RZ-EDU-01, vlan40, .114)                         ‚îÇ ‚îÇ
‚îÇ  ‚îÇ                                                                     ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ Apache   ‚îÇ  ‚îÇPostgreSQL ‚îÇ  ‚îÇ MeiliSearch  ‚îÇ  ‚îÇ Caddy / Nginx  ‚îÇ ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ Tika     ‚îÇ  ‚îÇ  (Meta-   ‚îÇ  ‚îÇ (Volltext-   ‚îÇ  ‚îÇ + Web-UI (SPA) ‚îÇ ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ Server   ‚îÇ  ‚îÇ   daten)  ‚îÇ  ‚îÇ   suche)     ‚îÇ  ‚îÇ                ‚îÇ ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ :9998    ‚îÇ  ‚îÇ  :5432    ‚îÇ  ‚îÇ  :7700       ‚îÇ  ‚îÇ  :8080         ‚îÇ ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ ‚îÇ
‚îÇ  ‚îÇ       ‚îÇ               ‚îÇ              ‚îÇ                             ‚îÇ ‚îÇ
‚îÇ  ‚îÇ       ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                             ‚îÇ ‚îÇ
‚îÇ  ‚îÇ               ‚îÇ                                                    ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  Python Indexer Service (edu-indexer.service)              ‚îÇ     ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  - Watchdog: √ºberwacht NAS-Shares via virtiofs            ‚îÇ     ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  - Tika: Textextraktion aus DOCX/PDF/PPTX/ODT/etc.       ‚îÇ     ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  - Ollama (HOST-01 via HTTP): KI-Klassifikation           ‚îÇ     ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  - PostgreSQL: Metadaten speichern                        ‚îÇ     ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  - MeiliSearch: Volltext + Metadaten indexieren            ‚îÇ     ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îÇ ‚îÇ
‚îÇ  ‚îÇ                          ‚îÇ virtiofs                                 ‚îÇ ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îÇ                             ‚îÇ                                            ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
‚îÇ  ‚îÇ  ZFS storage Pool ‚Äì NAS Shares (read-only f√ºr edu-search)        ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  /shared/shares/users/ina/schule/     ‚Üê Schulunterlagen Sync     ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  /storage/shares/bibliothek/          ‚Üê Bibliothek               ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  /storage/shares/dokumente/           ‚Üê Dokumente                ‚îÇ   ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
           ‚îÇ
           ‚îÇ HTTPS (Caddy Reverse Proxy auf HOST-02)
           ‚ñº
     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
     ‚îÇ  Browser     ‚îÇ   https://edu.czichy.com
     ‚îÇ  (Ina/PC)    ‚îÇ   Suchfeld + Filter + Ergebnisliste
     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Datenfluss bei neuer/ge√§nderter Datei

```text
 Ina speichert Datei auf NAS (Samba)
        ‚îÇ
        ‚ñº
 Watchdog erkennt √Ñnderung (inotify/polling via virtiofs)
        ‚îÇ
        ‚ñº
 Datei ‚Üí Apache Tika HTTP API (:9998)
        ‚îÇ   PUT /tika  ‚Üí  extrahierter Klartext
        ‚ñº
 Extrahierter Text ‚Üí Ollama HTTP API (HOST-01:11434)
        ‚îÇ   POST /api/generate
        ‚îÇ   Prompt: "Klassifiziere als JSON: Fach, Klasse, Thema, Typ, Niveau"
        ‚îÇ   Antwort: {"fach":"Englisch","klasse":"10","thema":"Macbeth","typ":"Arbeitsblatt","niveau":"B2"}
        ‚ñº
 Metadaten + Pfad ‚Üí PostgreSQL (INSERT/UPDATE documents)
        ‚îÇ
        ‚ñº
 Dokument + Metadaten ‚Üí MeiliSearch (POST /indexes/edu_documents/documents)
        ‚îÇ
        ‚ñº
 Ina sucht im Browser ‚Üí MeiliSearch liefert Treffer ‚Üí Klick √∂ffnet Datei via smb://
```

---

## 2. Entscheidung: Ollama auf HOST-01 vs. MicroVM

### ‚ö° Klare Empfehlung: **Ollama DIREKT auf HOST-01**

| Kriterium | Direkt auf HOST-01 | MicroVM |
|---|---|---|
| **GPU-Zugriff** | ‚úÖ Nativ via CUDA | ‚ùå Kein GPU-Passthrough in microvm.nix¬π |
| **Performance** | ‚úÖ Volle GPU-Leistung | ‚ùå Nur CPU (extrem langsam f√ºr LLM) |
| **Komplexit√§t** | ‚úÖ Einfache NixOS-Konfiguration | ‚ö†Ô∏è VFIO-Passthrough sehr aufw√§ndig |
| **RAM-Overhead** | ‚úÖ Kein VM-Overhead | ‚ùå +2GB f√ºr VM-Kernel etc. |
| **Bereits konfiguriert?** | ‚ùå Nein (ai.nix ist MicroVM) | ‚ö†Ô∏è ai.nix existiert, aber ohne GPU |
| **Wartung** | ‚úÖ Einfach | ‚ö†Ô∏è VFIO-Gruppen, Treiberprobleme |

> ¬π `microvm.nix` (astro/microvm.nix) unterst√ºtzt **keine PCI-Passthrough-Ger√§te** f√ºr QEMU-G√§ste
> im Standard-Setup. GPU-Passthrough erfordert vollst√§ndiges VFIO mit `vfio-pci`-Treiber-Binding,
> IOMMU-Gruppen-Isolation und manuelles QEMU-Kommando ‚Äì das widerspricht dem microvm.nix-Ansatz.

### Konsequenz f√ºr die bestehende `ai.nix` MicroVM

Die aktuelle `ai.nix` Guest-Konfiguration betreibt Ollama **ohne GPU** in einer MicroVM mit 16GB RAM
und 20 vCPUs. Das ist f√ºr LLM-Inference auf CPU extrem langsam. Der Refactoring-Plan:

- **Ollama** ‚Üí aus MicroVM raus, wird zum nativen Service auf HOST-01
- **Open-WebUI** ‚Üí kann optional in der MicroVM bleiben, greift dann auf `http://10.15.40.10:11434` zu
- Die MicroVM `ai` wird **entweder entfernt** oder nur noch f√ºr Open-WebUI genutzt (deutlich weniger RAM)

---

## 3. Komponenten-Details

### 3.1 NVIDIA-Treiber + CUDA (HOST-01, nativ)

| Eigenschaft | Wert |
|---|---|
| **NixOS-Module** | `hardware.nvidia`, `hardware.graphics` (ehemals opengl) |
| **Paket** | `config.boot.kernelPackages.nvidiaPackages.stable` |
| **Kernel-Modul** | `nvidia` in `boot.initrd.kernelModules` |
| **Persistenz** | Keine (Treiber im Nix-Store) |
| **Backup n√∂tig?** | ‚ùå Nein |

> **‚úÖ BEST√ÑTIGT:** GPU ist eine **NVIDIA GeForce GTX 1660 SUPER** (TU116, 6GB VRAM)
> an PCI-Adresse `2d:00.0`. Turing-Architektur ‚Üí `nvidiaPackages.stable` (propriet√§r) ist
> der richtige Treiberast. `open = false` da das Open-Source-Kernel-Modul TU116 nicht
> vollst√§ndig unterst√ºtzt. System hat **64GB RAM** (AMD Ryzen Matisse/Vermeer).

### 3.2 Ollama (HOST-01, nativ)

| Eigenschaft | Wert |
|---|---|
| **NixOS-Modul** | `services.ollama` |
| **Port** | `11434` |
| **Bind** | `0.0.0.0` (Firewall beschr√§nkt auf vlan40) |
| **GPU-Option** | `services.ollama.acceleration = "cuda"` |
| **Modell** | `mistral:7b` (gut f√ºr strukturierte JSON-Extraktion, ~4.1GB VRAM) |
| **Alt. Modelle** | `llama3.1:8b` (~4.7GB, passt noch in 6GB VRAM), `gemma2:9b` (zu gro√ü f√ºr 6GB!) |
| **VRAM-Limit** | 6GB (GTX 1660 SUPER) ‚Üí max. ~7B-8B Parameter-Modelle |
| **Daten** | `/var/lib/private/ollama` (Modelle, ~5-8 GB pro Modell auf Disk) |
| **Persistenz** | `environment.persistence."/state"` (impermanence) |
| **Backup n√∂tig?** | ‚ö†Ô∏è Optional ‚Äì Modelle k√∂nnen jederzeit `ollama pull` werden |

### 3.3 Apache Tika Server (MicroVM edu-search)

| Eigenschaft | Wert |
|---|---|
| **Paket** | `fetchurl` des offiziellen `tika-server-standard-X.Y.Z.jar` (~80MB) |
| **Betrieb** | Eigener `systemd`-Service im HTTP-Server-Modus (`java -jar`) |
| **Port** | `9998` (Standard Tika Server Port) |
| **Bind** | `127.0.0.1` (nur MicroVM-intern) |
| **JVM** | `pkgs.jre_minimal` (oder `pkgs.jdk21_headless`), Heap: `-Xmx512m` |
| **Unterst√ºtzt** | DOCX, PPTX, PDF, ODT, ODS, XLSX, MP3/MP4 (Meta), HTML, TXT, RTF |
| **Python-Client** | `python3Packages.tika-client` (in nixpkgs vorhanden) als Alternative |
| **Daten** | Stateless ‚Äì kein persistenter Zustand |
| **Backup n√∂tig?** | ‚ùå Nein |

> **‚úÖ GEKL√ÑRT:** `pkgs.apacheTika` existiert NICHT in nixpkgs. Verf√ºgbar sind:
> - `python3Packages.tika` (3.1.0) ‚Äì Python-Binding, startet Tika-Server selbst
> - `python3Packages.tika-client` (0.10.0) ‚Äì Client f√ºr laufenden Tika-Server
> - Wir verwenden `fetchurl` f√ºr das offizielle Apache Tika Server JAR + `jdk21_headless`

### 3.4 PostgreSQL (MicroVM edu-search)

| Eigenschaft | Wert |
|---|---|
| **NixOS-Modul** | `services.postgresql` |
| **Version** | 16 (aktuell in nixpkgs-unstable) |
| **Port** | `5432` |
| **Bind** | `127.0.0.1` |
| **Datenbank** | `edu_search` |
| **Tabelle** | `documents` (siehe Schema unten) |
| **Persistenz** | `/persist/var/lib/postgresql` (impermanence) |
| **Backup n√∂tig?** | ‚úÖ **Ja** ‚Äì enth√§lt alle KI-Klassifikationsergebnisse |

**Schema `documents`:**

```sql
CREATE TABLE documents (
    id              SERIAL PRIMARY KEY,
    filepath        TEXT UNIQUE NOT NULL,        -- Relativer Pfad auf NAS
    filename        TEXT NOT NULL,
    file_extension  TEXT,
    file_size       BIGINT,
    file_hash       TEXT,                        -- SHA256 zur √Ñnderungserkennung
    last_modified   TIMESTAMP WITH TIME ZONE,

    -- Von Tika extrahiert
    extracted_text  TEXT,                         -- Volltext (kann gro√ü sein)
    tika_content_type TEXT,                       -- MIME-Type laut Tika
    tika_metadata   JSONB,                       -- Alle Tika-Metadaten als JSON

    -- Von Ollama klassifiziert
    fach            TEXT,                         -- Englisch, Spanisch, Sonstige
    klasse          TEXT,                         -- 5-13
    thema           TEXT,                         -- Kurzbeschreibung
    typ             TEXT,                         -- Arbeitsblatt, Pr√§sentation, Test, Audio...
    niveau          TEXT,                         -- A1, A2, B1, B2, C1, C2
    ollama_raw      JSONB,                       -- Vollst√§ndige Ollama-Antwort

    -- Verwaltung
    indexed_at      TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    classification_status TEXT DEFAULT 'pending', -- pending, success, failed, skipped
    error_message   TEXT
);

CREATE INDEX idx_documents_fach ON documents(fach);
CREATE INDEX idx_documents_klasse ON documents(klasse);
CREATE INDEX idx_documents_typ ON documents(typ);
CREATE INDEX idx_documents_niveau ON documents(niveau);
CREATE INDEX idx_documents_status ON documents(classification_status);
```

### 3.5 MeiliSearch (MicroVM edu-search)

| Eigenschaft | Wert |
|---|---|
| **NixOS-Modul** | `services.meilisearch` |
| **Port** | `7700` |
| **Bind** | `0.0.0.0` (erreichbar f√ºr Web-UI und API) |
| **Index** | `edu_documents` |
| **Felder** | `id`, `filename`, `filepath`, `content`, `fach`, `klasse`, `thema`, `typ`, `niveau`, `smb_url` |
| **Filterable** | `fach`, `klasse`, `typ`, `niveau` |
| **Sortable** | `klasse`, `filename`, `last_modified` |
| **Persistenz** | `/persist/var/lib/meilisearch` (impermanence) |
| **Backup n√∂tig?** | ‚ö†Ô∏è Kann aus PostgreSQL + NAS-Daten rebuilt werden |

> **Warum MeiliSearch statt Elasticsearch?**
> - MeiliSearch ist bereits teilweise konfiguriert (`meilisearch.nix` existiert)
> - Deutlich leichter (RAM: ~100MB vs. ~2GB f√ºr Elasticsearch)
> - Bessere NixOS-Integration (`services.meilisearch` ist ein offizielles Modul)
> - Typo-tolerante Suche out-of-the-box (perfekt f√ºr Ina)
> - Faceted Search / Filterbare Attribute = ideal f√ºr Dropdowns
> - Kein Docker n√∂tig (im Gegensatz zu Elasticsearch in NixOS)
> - Falls doch Elasticsearch gew√ºnscht: Plan ist modular, Austausch m√∂glich

### 3.6 Python Indexer Service (MicroVM edu-search)

| Eigenschaft | Wert |
|---|---|
| **Betrieb** | `systemd`-Service (`edu-indexer.service`) |
| **Sprache** | Python 3.12 mit Nix-verwalteter Umgebung |
| **Abh√§ngigkeiten** | `watchdog`, `requests` (oder `tika-client`), `psycopg2`, `meilisearch-python` |
| **Funktion** | Datei-Watcher ‚Üí Tika ‚Üí Ollama ‚Üí PostgreSQL ‚Üí MeiliSearch |
| **Persistenz** | `/persist/var/lib/edu-indexer/state.json` (Indexierungs-Status) |
| **Backup n√∂tig?** | ‚ö†Ô∏è `state.json` optional ‚Äì Re-Index aus NAS jederzeit m√∂glich |

**Ollama-Prompt f√ºr die Klassifikation:**

```text
Du bist ein Klassifikations-Assistent f√ºr Unterrichtsmaterialien einer Lehrerin
f√ºr Englisch und Spanisch. Analysiere den folgenden Text und extrahiere die Metadaten.

Antworte NUR mit validem JSON, keine Erkl√§rungen:
{
  "fach": "Englisch" oder "Spanisch" oder "Sonstige",
  "klasse": "5" bis "13" oder "unbekannt",
  "thema": "kurze Beschreibung des Themas (max 50 Zeichen)",
  "typ": "Arbeitsblatt" oder "Pr√§sentation" oder "Test" oder "Klausur" oder "Audio" oder "Video" oder "Bild" oder "Sonstiges",
  "niveau": "A1" oder "A2" oder "B1" oder "B2" oder "C1" oder "C2" oder "unbekannt"
}

TEXT:
{extracted_text_first_3000_chars}

DATEINAME: {filename}
```

### 3.7 Web-UI (MicroVM edu-search)

| Eigenschaft | Wert |
|---|---|
| **Framework** | Statische SPA mit InstantSearch.js + MeiliSearch JS Client |
| **Server** | Nginx (als statischer Fileserver) oder Caddy |
| **Port** | `8080` |
| **Features** | Suchfeld (Volltext), Dropdowns (Fach/Klasse/Typ/Niveau), Ergebnisliste |
| **Datei-√ñffnung** | Link als `smb://HL-3-RZ-SMB-01/shares/...` (√∂ffnet im Explorer) |
| **Persistenz** | Keine (statische Dateien im Nix-Store) |
| **Backup n√∂tig?** | ‚ùå Nein (ist Nix-konfiguriert) |

---

## 4. Datei- und Verzeichnisstruktur im Nix-Repo

### Neue und ge√§nderte Dateien

```text
nixos/
‚îú‚îÄ‚îÄ hosts/HL-1-MRZ-HOST-01/
‚îÇ   ‚îú‚îÄ‚îÄ modules/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ gpu.nix                          ‚Üê NEU: NVIDIA-Treiber + CUDA
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ollama.nix                       ‚Üê NEU: Ollama Service nativ auf HOST-01
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ default.nix                      ‚Üê √ÑNDERN: gpu.nix + ollama.nix importieren
‚îÇ   ‚îú‚îÄ‚îÄ guests/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ edu-search.nix                   ‚Üê NEU: MicroVM-Definition
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ edu-search/
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ tika.nix                     ‚Üê NEU: Apache Tika systemd Service
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ postgresql.nix               ‚Üê NEU: PostgreSQL mit Schema
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ meilisearch.nix              ‚Üê NEU: MeiliSearch Konfiguration
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ indexer.nix                  ‚Üê NEU: Python Indexer systemd Service
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ indexer.py                   ‚Üê NEU: Python Indexer Skript
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ webui.nix                    ‚Üê NEU: Nginx + statische SPA
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ webui/                       ‚Üê NEU: HTML/CSS/JS der Suchoberfl√§che
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ index.html
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ style.css
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ app.js
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ backup.nix                   ‚Üê NEU: Restic Backup f√ºr PostgreSQL + MeiliSearch
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ai.nix                           ‚Üê √ÑNDERN: Ollama entfernen, nur Open-WebUI
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ meilisearch.nix                  ‚Üê ENTFERNEN/ERSETZEN: alte unfertige Konfiguration
‚îÇ   ‚îú‚îÄ‚îÄ guests.nix                           ‚Üê √ÑNDERN: edu-search MicroVM hinzuf√ºgen
‚îÇ   ‚îî‚îÄ‚îÄ default.nix                          ‚Üê evtl. √ÑNDERN: Module-Import
‚îú‚îÄ‚îÄ globals.nix                              ‚Üê √ÑNDERN: HL-3-RZ-EDU-01 Host-ID hinzuf√ºgen
‚îî‚îÄ‚îÄ PLAN_EDU_SEARCH.md                       ‚Üê DIESE DATEI
```

### Beziehung zur bestehenden Infrastruktur

| Bestehend | Aktion | Begr√ºndung |
|---|---|---|
| `guests/ai.nix` | Refactoring | Ollama raus (‚Üí HOST-01 nativ), Open-WebUI bleibt |
| `guests/meilisearch.nix` | Ersetzen | Alte unfertige Config, wird durch edu-search ersetzt |
| `guests/meilisearch/` | Ersetzen | Altes Python-Skript, wird durch neuen Indexer ersetzt |
| `guests/samba.nix` | Unver√§ndert | NAS-Shares bleiben wie sie sind |
| `guests/sync_ina.nix` | Unver√§ndert | Syncthing f√ºr Ina bleibt parallel |
| `guests.nix` | Erweitern | Neue MicroVM `edu-search` eintragen |
| `globals.nix` | Erweitern | Host-ID `HL-3-RZ-EDU-01.id = 114` in vlan40 |

---

## 5. Phase 1 ‚Äì Fundament (1-2 Wochenenden)

### 5.1 NVIDIA-Treiber auf HOST-01

**Datei: `hosts/HL-1-MRZ-HOST-01/modules/gpu.nix`**

```nix
# GPU-Konfiguration f√ºr NVIDIA GeForce GTX 1660 SUPER (TU116) auf HOST-01
# PCI: 2d:00.0, Turing-Architektur, 6GB VRAM
# BEST√ÑTIGT: lspci zeigt "TU116 [GeForce GTX 1660 SUPER] (rev a1)"
{ config, lib, pkgs, ... }: {
  # NVIDIA-Treiber (headless, kein X11/Wayland n√∂tig auf Server)
  hardware.nvidia = {
    modesetting.enable = true;
    powerManagement.enable = false;
    # TU116 (Turing) braucht den propriet√§ren Treiber, NICHT open
    open = false;
    nvidiaSettings = false;  # Kein GUI-Tool auf Server
    package = config.boot.kernelPackages.nvidiaPackages.stable;
  };

  hardware.graphics = {
    enable = true;
  };

  # Kernel-Module
  boot.initrd.kernelModules = [ "nvidia" ];
  boot.extraModulePackages = [ config.boot.kernelPackages.nvidiaPackages.stable ];

  # CUDA verf√ºgbar machen + GPU-Monitoring
  environment.systemPackages = with pkgs; [
    nvtopPackages.nvidia   # GPU-Monitoring (wie htop f√ºr GPU)
    cudaPackages.cuda_nvcc  # Optional: CUDA Compiler f√ºr Tests
  ];

  # nvidia-smi soll funktionieren
  services.xserver.videoDrivers = [ "nvidia" ];
  # Auf headless-Servern: Kein Display-Manager, aber Treiber wird geladen
}
```

### 5.2 Ollama nativ auf HOST-01

**Datei: `hosts/HL-1-MRZ-HOST-01/modules/ollama.nix`**

```nix
# Ollama LLM Service direkt auf HOST-01 (GPU-beschleunigt)
{ config, pkgs, ... }: {
  services.ollama = {
    enable = true;
    host = "0.0.0.0";
    port = 11434;
    acceleration = "cuda";  # GPU-Beschleunigung via NVIDIA CUDA
    # loadModels = [ "mistral:7b" ];  # Optional: Modell beim Start laden
  };

  # Firewall: Ollama nur aus vlan40 (Server-VLAN) erreichbar
  networking.firewall.allowedTCPPorts = [ 11434 ];

  # Impermanence: Ollama-Daten (Modelle) persistent machen
  environment.persistence."/state".directories = [
    {
      directory = "/var/lib/private/ollama";
      mode = "0700";
    }
  ];
}
```

**Datei: `hosts/HL-1-MRZ-HOST-01/modules/default.nix` (anpassen):**

```nix
{
  imports = [
    ./profiles.nix
    ./security.nix
    ./services.nix
    ./system.nix
    ./gpu.nix      # NEU
    ./ollama.nix   # NEU
  ];
}
```

### 5.3 MicroVM edu-search registrieren

**Datei: `globals.nix` ‚Äì neue Host-ID hinzuf√ºgen:**

```nix
# Im vlan40-Block hinzuf√ºgen:
hosts.HL-3-RZ-EDU-01.id = 114;
```

**Datei: `guests.nix` ‚Äì neue MicroVM eintragen:**

```nix
# Im Block nach den bestehenden mkMicrovm-Aufrufen:
// mkMicrovm "edu-search" "HL-3-RZ-EDU-01" "enp38s0" "02:08:27:ee:9e:16" "vlan40" {
  enableSharedDataset = true;   # Zugriff auf /shared (Inas Dateien)
  enableStorageDataset = true;  # Zugriff auf /storage (Bibliothek, Dokumente)
}
```

### 5.4 MicroVM edu-search Grundkonfiguration

**Datei: `hosts/HL-1-MRZ-HOST-01/guests/edu-search.nix`**

```nix
{
  config,
  globals,
  secretsPath,
  hostName,
  lib,
  pkgs,
  ...
}: let
  eduDomain = "edu.${globals.domains.me}";
  certloc = "/var/lib/acme-sync/czichy.com";
  ollamaHost = globals.net.vlan40.hosts.HL-1-MRZ-HOST-01.ipv4;
in {
  microvm.mem = 1024 * 6;  # 6 GB RAM (Tika+PG+Meili+Python) ‚Äì 64GB Host hat genug
  microvm.vcpu = 4;

  networking.hostName = hostName;

  # NAS-Shares als virtiofs in die MicroVM mounten (read-only)
  microvm.shares = [
    {
      source = "/shared/shares/users/ina";
      mountPoint = "/nas/ina";
      tag = "edu-ina";
      proto = "virtiofs";
    }
    {
      source = "/storage/shares/bibliothek";
      mountPoint = "/nas/bibliothek";
      tag = "edu-bib";
      proto = "virtiofs";
    }
    {
      source = "/storage/shares/dokumente";
      mountPoint = "/nas/dokumente";
      tag = "edu-dok";
      proto = "virtiofs";
    }
  ];

  imports = [
    ./edu-search/tika.nix
    ./edu-search/postgresql.nix
    ./edu-search/meilisearch.nix
    ./edu-search/indexer.nix
    ./edu-search/webui.nix
    ./edu-search/backup.nix
  ];

  # Firewall: Web-UI erreichbar machen
  networking.firewall.allowedTCPPorts = [ 8080 7700 ];

  # Impermanence
  environment.persistence."/persist".files = [
    "/etc/ssh/ssh_host_rsa_key"
    "/etc/ssh/ssh_host_rsa_key.pub"
  ];

  # Reverse Proxy via Caddy auf HOST-02
  nodes.HL-1-MRZ-HOST-02-caddy = {
    services.caddy = {
      virtualHosts."${eduDomain}".extraConfig = ''
        reverse_proxy http://${globals.net.vlan40.hosts."HL-3-RZ-EDU-01".ipv4}:8080
        tls ${certloc}/fullchain.pem ${certloc}/key.pem {
           protocols tls1.3
        }
        import czichy_headers
      '';
    };
  };

  fileSystems = lib.mkMerge [
    { "/state".neededForBoot = true; }
  ];

  systemd.network.enable = true;
  system.stateVersion = "24.05";
}
```

### 5.5 Apache Tika Service

**Datei: `hosts/HL-1-MRZ-HOST-01/guests/edu-search/tika.nix`**

> **‚úÖ GEKL√ÑRT:** `pkgs.apacheTika` existiert NICHT in nixpkgs-unstable. Wir verwenden
> `fetchurl` um das offizielle JAR direkt von Apache herunterzuladen.

```nix
# Apache Tika als HTTP-Server f√ºr Textextraktion
# HINWEIS: pkgs.apacheTika existiert nicht in nixpkgs, daher fetchurl des JAR
{ pkgs, lib, ... }: let
  tikaPort = 9998;
  tikaVersion = "3.1.0";

  # Tika Server JAR direkt von Apache herunterladen
  # SHA256-Hash muss beim ersten Build via `nix-prefetch-url` ermittelt werden:
  #   nix-prefetch-url https://dlcdn.apache.org/tika/${tikaVersion}/tika-server-standard-${tikaVersion}.jar
  tika-server-jar = pkgs.fetchurl {
    url = "https://dlcdn.apache.org/tika/${tikaVersion}/tika-server-standard-${tikaVersion}.jar";
    # PLATZHALTER ‚Äì muss vor dem ersten Build ersetzt werden!
    hash = "sha256-AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA=";
  };
in {
  # Java-Runtime f√ºr Tika
  environment.systemPackages = [ pkgs.jdk21_headless ];

  # Tika als systemd Service (kein NixOS-Modul vorhanden, daher manuell)
  systemd.services.tika-server = {
    description = "Apache Tika Server for text extraction";
    after = [ "network.target" ];
    wantedBy = [ "multi-user.target" ];

    serviceConfig = {
      Type = "simple";
      Restart = "on-failure";
      RestartSec = "10s";
      DynamicUser = true;
      StateDirectory = "tika";

      ExecStart = ''
        ${pkgs.jdk21_headless}/bin/java \
          -Xmx512m \
          -jar ${tika-server-jar} \
          --host 127.0.0.1 \
          --port ${toString tikaPort}
      '';

      # Sicherheit: Minimale Rechte
      NoNewPrivileges = true;
      ProtectSystem = "strict";
      ProtectHome = true;
      PrivateTmp = true;
    };
  };

  # HINWEIS: Tika ist stateless, kein Persistenz/Backup n√∂tig
}
```

> **Alternative:** Falls der `fetchurl`-Ansatz Probleme macht (z.B. Hash-√Ñnderungen bei
> Apache-Mirror-Updates), kann stattdessen `python3Packages.tika` (v3.1.0) verwendet werden.
> Dieses Python-Paket managed den Tika-Server-Download und -Start selbst. Der Nachteil:
> Weniger Kontrolle √ºber den Serverprozess und kein separater systemd-Service.

### 5.6 PostgreSQL mit Schema

**Datei: `hosts/HL-1-MRZ-HOST-01/guests/edu-search/postgresql.nix`**

```nix
# PostgreSQL f√ºr Metadaten-Speicherung
{ config, pkgs, lib, ... }: {
  services.postgresql = {
    enable = true;
    package = pkgs.postgresql_16;
    settings = {
      listen_addresses = "127.0.0.1";
      port = 5432;
      # Leichtgewichtige Einstellungen f√ºr MicroVM
      shared_buffers = "128MB";
      work_mem = "8MB";
      max_connections = 20;
    };

    # Datenbank und User automatisch anlegen
    ensureDatabases = [ "edu_search" ];
    ensureUsers = [
      {
        name = "edu_indexer";
        ensureDBOwnership = true;
      }
    ];

    # Schema beim ersten Start anlegen
    initialScript = pkgs.writeText "edu-search-init.sql" ''
      -- Nur ausgef√ºhrt wenn DB neu erstellt wird
      \c edu_search;

      CREATE TABLE IF NOT EXISTS documents (
          id              SERIAL PRIMARY KEY,
          filepath        TEXT UNIQUE NOT NULL,
          filename        TEXT NOT NULL,
          file_extension  TEXT,
          file_size       BIGINT,
          file_hash       TEXT,
          last_modified   TIMESTAMP WITH TIME ZONE,

          extracted_text  TEXT,
          tika_content_type TEXT,
          tika_metadata   JSONB,

          fach            TEXT,
          klasse          TEXT,
          thema           TEXT,
          typ             TEXT,
          niveau          TEXT,
          ollama_raw      JSONB,

          indexed_at      TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
          classification_status TEXT DEFAULT 'pending',
          error_message   TEXT
      );

      CREATE INDEX IF NOT EXISTS idx_doc_fach ON documents(fach);
      CREATE INDEX IF NOT EXISTS idx_doc_klasse ON documents(klasse);
      CREATE INDEX IF NOT EXISTS idx_doc_typ ON documents(typ);
      CREATE INDEX IF NOT EXISTS idx_doc_niveau ON documents(niveau);
      CREATE INDEX IF NOT EXISTS idx_doc_status ON documents(classification_status);
      CREATE INDEX IF NOT EXISTS idx_doc_hash ON documents(file_hash);

      GRANT ALL PRIVILEGES ON DATABASE edu_search TO edu_indexer;
      GRANT ALL PRIVILEGES ON ALL TABLES IN SCHEMA public TO edu_indexer;
      GRANT ALL PRIVILEGES ON ALL SEQUENCES IN SCHEMA public TO edu_indexer;
    '';
  };

  # Impermanence: PostgreSQL-Daten persistent
  environment.persistence."/persist".directories = [
    {
      directory = "/var/lib/postgresql";
      user = "postgres";
      group = "postgres";
      mode = "0750";
    }
  ];
}
```

---

## 6. Phase 2 ‚Äì Suche & Indexierung (1 Wochenende)

### 6.1 MeiliSearch Konfiguration

**Datei: `hosts/HL-1-MRZ-HOST-01/guests/edu-search/meilisearch.nix`**

```nix
# MeiliSearch f√ºr Volltext- und Facettensuche
{ config, pkgs, lib, ... }: let
  meiliPort = 7700;
in {
  services.meilisearch = {
    enable = true;
    package = pkgs.meilisearch;
    # WICHTIG: Master-Key via agenix Secret verwalten!
    # Vorerst Platzhalter, in Phase 4 durch Secret ersetzen
    environment = "production";
    listenAddress = "0.0.0.0";
    listenPort = meiliPort;
  };

  # Impermanence: MeiliSearch-Daten persistent
  environment.persistence."/persist".directories = [
    {
      directory = "/var/lib/meilisearch";
      user = "meilisearch";
      group = "meilisearch";
      mode = "0700";
    }
  ];
}
```

> **MeiliSearch Index-Konfiguration** (wird vom Python-Indexer beim Start gesetzt):
> - `filterableAttributes`: `["fach", "klasse", "typ", "niveau"]`
> - `sortableAttributes`: `["klasse", "filename", "last_modified"]`
> - `searchableAttributes`: `["content", "filename", "thema", "fach"]`
> - `displayedAttributes`: `["id", "filename", "filepath", "fach", "klasse", "thema", "typ", "niveau", "smb_url", "last_modified"]`
>   (Wichtig: `content` wird NICHT in displayedAttributes aufgenommen, um die Antwortgr√∂√üe klein zu halten)

### 6.2 Python Indexer Service

**Datei: `hosts/HL-1-MRZ-HOST-01/guests/edu-search/indexer.nix`**

```nix
# Python-basierter Indexer: Watchdog ‚Üí Tika ‚Üí Ollama ‚Üí PostgreSQL ‚Üí MeiliSearch
{ config, pkgs, lib, globals, ... }: let
  ollamaHost = "http://${globals.net.vlan40.hosts.HL-1-MRZ-HOST-01.ipv4}:11434";
  tikaUrl = "http://127.0.0.1:9998";
  meiliUrl = "http://127.0.0.1:7700";
  # Alle zu √ºberwachenden NAS-Verzeichnisse
  watchDirs = "/nas/ina/schule,/nas/bibliothek,/nas/dokumente";
  # SMB-Basis-URL f√ºr die Web-UI Links
  smbBase = "smb://HL-3-RZ-SMB-01/shares";

  pythonEnv = pkgs.python3.withPackages (ps: with ps; [
    watchdog          # Dateisystem-√úberwachung
    requests          # HTTP-Client f√ºr Tika + Ollama
    psycopg2          # PostgreSQL-Client
    meilisearch       # MeiliSearch Python Client (PyPI: meilisearch)
  ]);

  indexerScript = ./indexer.py;
in {
  systemd.services.edu-indexer = {
    description = "Edu-Search Document Indexer (Tika + Ollama + MeiliSearch)";
    after = [
      "network-online.target"
      "postgresql.service"
      "meilisearch.service"
      "tika-server.service"
    ];
    requires = [
      "postgresql.service"
      "meilisearch.service"
      "tika-server.service"
    ];
    wantedBy = [ "multi-user.target" ];

    serviceConfig = {
      Type = "simple";
      Restart = "on-failure";
      RestartSec = "30s";
      User = "edu-indexer";
      Group = "users";

      ExecStart = "${pythonEnv}/bin/python ${indexerScript}";

      Environment = [
        "OLLAMA_URL=${ollamaHost}"
        "TIKA_URL=${tikaUrl}"
        "MEILI_URL=${meiliUrl}"
        "MEILI_INDEX=edu_documents"
        "WATCH_DIRS=${watchDirs}"
        "SMB_BASE=${smbBase}"
        "DB_HOST=127.0.0.1"
        "DB_PORT=5432"
        "DB_NAME=edu_search"
        "DB_USER=edu_indexer"
        "STATE_FILE=/var/lib/edu-indexer/state.json"
        "OLLAMA_MODEL=mistral:7b"
        # Polling-Interval in Sekunden (virtiofs sendet nicht immer inotify)
        "POLL_INTERVAL=60"
      ];

      # Sicherheit
      NoNewPrivileges = true;
      ProtectHome = true;
      PrivateTmp = true;
      ReadOnlyPaths = [ "/nas" ];
      ReadWritePaths = [ "/var/lib/edu-indexer" ];
    };
  };

  # User f√ºr den Indexer
  users.users.edu-indexer = {
    isSystemUser = true;
    group = "users";
    home = "/var/lib/edu-indexer";
    createHome = true;
  };

  # Impermanence
  environment.persistence."/persist".directories = [
    {
      directory = "/var/lib/edu-indexer";
      user = "edu-indexer";
      group = "users";
      mode = "0750";
    }
  ];
}
```

### 6.3 Python Indexer Skript (Kernlogik)

**Datei: `hosts/HL-1-MRZ-HOST-01/guests/edu-search/indexer.py`**

```python
#!/usr/bin/env python3
"""
Edu-Search Document Indexer
===========================
Pipeline: Datei-Watcher ‚Üí Tika (Text) ‚Üí Ollama (KI-Klassifikation) ‚Üí PostgreSQL + MeiliSearch

Dieses Skript:
1. √úberwacht NAS-Verzeichnisse auf neue/ge√§nderte/gel√∂schte Dateien
2. Extrahiert Text via Apache Tika HTTP API
3. Klassifiziert via Ollama (Fach, Klasse, Thema, Typ, Niveau)
4. Speichert Metadaten in PostgreSQL
5. Indexiert in MeiliSearch f√ºr die Web-Suche
"""
import os
import sys
import json
import time
import hashlib
import logging
import re
from pathlib import Path
from datetime import datetime, timezone

import requests
import psycopg2
import psycopg2.extras
import meilisearch
from watchdog.observers.polling import PollingObserver
from watchdog.events import FileSystemEventHandler

# --- Konfiguration aus Umgebungsvariablen ---
OLLAMA_URL = os.getenv("OLLAMA_URL", "http://10.15.40.10:11434")
OLLAMA_MODEL = os.getenv("OLLAMA_MODEL", "mistral:7b")
TIKA_URL = os.getenv("TIKA_URL", "http://127.0.0.1:9998")
MEILI_URL = os.getenv("MEILI_URL", "http://127.0.0.1:7700")
MEILI_KEY = os.getenv("MEILI_KEY", "")
MEILI_INDEX = os.getenv("MEILI_INDEX", "edu_documents")
WATCH_DIRS = os.getenv("WATCH_DIRS", "/nas/ina/schule").split(",")
SMB_BASE = os.getenv("SMB_BASE", "smb://HL-3-RZ-SMB-01/shares")
DB_HOST = os.getenv("DB_HOST", "127.0.0.1")
DB_PORT = os.getenv("DB_PORT", "5432")
DB_NAME = os.getenv("DB_NAME", "edu_search")
DB_USER = os.getenv("DB_USER", "edu_indexer")
STATE_FILE = os.getenv("STATE_FILE", "/var/lib/edu-indexer/state.json")
POLL_INTERVAL = int(os.getenv("POLL_INTERVAL", "60"))

# Unterst√ºtzte Dateierweiterungen
SUPPORTED_EXTENSIONS = {
    ".pdf", ".docx", ".doc", ".pptx", ".ppt", ".odt", ".odp", ".ods",
    ".xlsx", ".xls", ".rtf", ".txt", ".html", ".htm", ".epub",
    ".mp3", ".mp4", ".m4a", ".wav",  # Audio/Video: nur Metadaten
}

logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s [%(levelname)s] %(message)s",
    handlers=[logging.StreamHandler(sys.stdout)]
)
log = logging.getLogger("edu-indexer")

# --- Hilfsfunktionen ---

def file_hash(filepath: str) -> str:
    """SHA256-Hash einer Datei berechnen."""
    h = hashlib.sha256()
    with open(filepath, "rb") as f:
        for chunk in iter(lambda: f.read(8192), b""):
            h.update(chunk)
    return h.hexdigest()

def extract_text_tika(filepath: str) -> tuple[str, str, dict]:
    """Text via Apache Tika extrahieren. Returns (text, content_type, metadata)."""
    try:
        with open(filepath, "rb") as f:
            # Tika /tika Endpoint: gibt Plaintext zur√ºck
            resp = requests.put(
                f"{TIKA_URL}/tika",
                data=f,
                headers={"Accept": "text/plain"},
                timeout=120,
            )
            resp.raise_for_status()
            text = resp.text.strip()

        # Metadaten separat holen
        with open(filepath, "rb") as f:
            meta_resp = requests.put(
                f"{TIKA_URL}/meta",
                data=f,
                headers={"Accept": "application/json"},
                timeout=60,
            )
            meta_resp.raise_for_status()
            metadata = meta_resp.json()
            content_type = metadata.get("Content-Type", "unknown")

        return text, content_type, metadata
    except Exception as e:
        log.error(f"Tika-Extraktion fehlgeschlagen f√ºr {filepath}: {e}")
        return "", "error", {}


def classify_with_ollama(text: str, filename: str) -> dict:
    """
    Text via Ollama LLM klassifizieren.
    Gibt ein Dict mit fach, klasse, thema, typ, niveau zur√ºck.
    """
    # Nur die ersten 3000 Zeichen senden (Token-Limit + Kosten)
    snippet = text[:3000] if text else "(kein Text extrahiert)"

    prompt = f"""Du bist ein Klassifikations-Assistent f√ºr Unterrichtsmaterialien einer Lehrerin
f√ºr Englisch und Spanisch. Analysiere den folgenden Text und extrahiere die Metadaten.

Antworte NUR mit validem JSON, keine Erkl√§rungen davor oder danach:
{{
  "fach": "Englisch" oder "Spanisch" oder "Sonstige",
  "klasse": "5" bis "13" oder "unbekannt",
  "thema": "kurze Beschreibung des Themas (max 50 Zeichen)",
  "typ": "Arbeitsblatt" oder "Pr√§sentation" oder "Test" oder "Klausur" oder "Audio" oder "Video" oder "Bild" oder "Sonstiges",
  "niveau": "A1" oder "A2" oder "B1" oder "B2" oder "C1" oder "C2" oder "unbekannt"
}}

DATEINAME: {filename}

TEXT:
{snippet}"""

    try:
        resp = requests.post(
            f"{OLLAMA_URL}/api/generate",
            json={
                "model": OLLAMA_MODEL,
                "prompt": prompt,
                "stream": False,
                "format": "json",
                "options": {"temperature": 0.1, "num_predict": 256},
            },
            timeout=120,
        )
        resp.raise_for_status()
        raw = resp.json().get("response", "")
        # JSON aus der Antwort extrahieren (Ollama gibt manchmal Wrapper-Text)
        match = re.search(r"\{[^{}]+\}", raw, re.DOTALL)
        if match:
            result = json.loads(match.group())
            return {
                "fach": result.get("fach", "unbekannt"),
                "klasse": result.get("klasse", "unbekannt"),
                "thema": result.get("thema", "")[:100],
                "typ": result.get("typ", "Sonstiges"),
                "niveau": result.get("niveau", "unbekannt"),
                "_raw": raw,
            }
        else:
            log.warning(f"Ollama-Antwort enthielt kein JSON: {raw[:200]}")
            return {"fach": "unbekannt", "klasse": "unbekannt", "thema": "",
                    "typ": "Sonstiges", "niveau": "unbekannt", "_raw": raw}
    except Exception as e:
        log.error(f"Ollama-Klassifikation fehlgeschlagen: {e}")
        return {"fach": "error", "klasse": "error", "thema": str(e)[:100],
                "typ": "error", "niveau": "error", "_raw": ""}


def filepath_to_smb_url(filepath: str) -> str:
    """Konvertiert einen lokalen NAS-Pfad in eine smb:// URL."""
    # /nas/ina/schule/Englisch/test.docx -> smb://HL-3-RZ-SMB-01/shares/users/ina/schule/Englisch/test.docx
    path_map = {
        "/nas/ina": f"{SMB_BASE}/users/ina",
        "/nas/bibliothek": f"{SMB_BASE}/bibliothek",
        "/nas/dokumente": f"{SMB_BASE}/dokumente",
    }
    for local_prefix, smb_prefix in path_map.items():
        if filepath.startswith(local_prefix):
            return filepath.replace(local_prefix, smb_prefix, 1)
    return filepath


def get_db_connection():
    """PostgreSQL-Verbindung herstellen."""
    return psycopg2.connect(
        host=DB_HOST, port=DB_PORT, dbname=DB_NAME, user=DB_USER
    )


def get_meili_client():
    """MeiliSearch-Client erstellen und Index konfigurieren."""
    client = meilisearch.Client(MEILI_URL, MEILI_KEY or None)
    index = client.index(MEILI_INDEX)
    # Index-Einstellungen setzen (idempotent)
    index.update_filterable_attributes(["fach", "klasse", "typ", "niveau"])
    index.update_sortable_attributes(["klasse", "filename", "last_modified"])
    index.update_searchable_attributes(["content", "filename", "thema", "fach"])
    index.update_displayed_attributes([
        "id", "filename", "filepath", "fach", "klasse", "thema",
        "typ", "niveau", "smb_url", "last_modified", "file_extension",
    ])
    return index


# --- Kernlogik: Einzelne Datei verarbeiten ---

def process_file(filepath: str, db_conn, meili_index):
    """Eine einzelne Datei durch die komplette Pipeline schicken."""
    path = Path(filepath)

    # Nur unterst√ºtzte Dateien
    if path.suffix.lower() not in SUPPORTED_EXTENSIONS:
        return

    # Dateigr√∂√üe und Hash pr√ºfen
    try:
        stat = path.stat()
        current_hash = file_hash(filepath)
    except OSError as e:
        log.warning(f"Datei nicht lesbar: {filepath}: {e}")
        return

    # Pr√ºfe ob bereits indexiert und unver√§ndert
    with db_conn.cursor(cursor_factory=psycopg2.extras.DictCursor) as cur:
        cur.execute("SELECT file_hash FROM documents WHERE filepath = %s", (filepath,))
        row = cur.fetchone()
        if row and row["file_hash"] == current_hash:
            log.debug(f"Unver√§ndert, √ºberspringe: {filepath}")
            return

    log.info(f"Verarbeite: {filepath}")

    # 1. Text extrahieren via Tika
    text, content_type, tika_meta = extract_text_tika(filepath)

    # 2. KI-Klassifikation via Ollama
    if text:
        classification = classify_with_ollama(text, path.name)
        status = "success"
    else:
        classification = {"fach": "unbekannt", "klasse": "unbekannt",
                          "thema": "kein Text extrahiert", "typ": "Sonstiges",
                          "niveau": "unbekannt", "_raw": ""}
        status = "skipped" if path.suffix.lower() in {".mp3", ".mp4", ".m4a", ".wav"} else "failed"

    # 3. In PostgreSQL speichern (UPSERT)
    with db_conn.cursor() as cur:
        cur.execute("""
            INSERT INTO documents (
                filepath, filename, file_extension, file_size, file_hash,
                last_modified, extracted_text, tika_content_type, tika_metadata,
                fach, klasse, thema, typ, niveau, ollama_raw,
                indexed_at, classification_status
            ) VALUES (
                %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s
            )
            ON CONFLICT (filepath) DO UPDATE SET
                filename = EXCLUDED.filename,
                file_extension = EXCLUDED.file_extension,
                file_size = EXCLUDED.file_size,
                file_hash = EXCLUDED.file_hash,
                last_modified = EXCLUDED.last_modified,
                extracted_text = EXCLUDED.extracted_text,
                tika_content_type = EXCLUDED.tika_content_type,
                tika_metadata = EXCLUDED.tika_metadata,
                fach = EXCLUDED.fach,
                klasse = EXCLUDED.klasse,
                thema = EXCLUDED.thema,
                typ = EXCLUDED.typ,
                niveau = EXCLUDED.niveau,
                ollama_raw = EXCLUDED.ollama_raw,
                indexed_at = EXCLUDED.indexed_at,
                classification_status = EXCLUDED.classification_status
        """, (
            filepath, path.name, path.suffix.lower(), stat.st_size, current_hash,
            datetime.fromtimestamp(stat.st_mtime, tz=timezone.utc),
            text[:50000] if text else None,  # Limit f√ºr DB
            content_type, json.dumps(tika_meta),
            classification.get("fach"), classification.get("klasse"),
            classification.get("thema"), classification.get("typ"),
            classification.get("niveau"), json.dumps(classification.get("_raw", "")),
            datetime.now(timezone.utc), status,
        ))
    db_conn.commit()

    # 4. In MeiliSearch indexieren
    smb_url = filepath_to_smb_url(filepath)
    doc_id = current_hash[:16]  # Kurzer deterministischer ID
    meili_doc = {
        "id": doc_id,
        "filename": path.name,
        "filepath": filepath,
        "file_extension": path.suffix.lower(),
        "smb_url": smb_url,
        "content": text[:10000] if text else "",  # Limit f√ºr Suchindex
        "fach": classification.get("fach", "unbekannt"),
        "klasse": classification.get("klasse", "unbekannt"),
        "thema": classification.get("thema", ""),
        "typ": classification.get("typ", "Sonstiges"),
        "niveau": classification.get("niveau", "unbekannt"),
        "last_modified": int(stat.st_mtime),
    }
    try:
        meili_index.add_documents([meili_doc])
        log.info(f"Indexiert: {path.name} -> {classification.get('fach')}/{classification.get('thema')}")
    except Exception as e:
        log.error(f"MeiliSearch-Fehler f√ºr {filepath}: {e}")


def delete_from_index(filepath: str, db_conn, meili_index):
    """Eine gel√∂schte Datei aus PostgreSQL und MeiliSearch entfernen."""
    with db_conn.cursor() as cur:
        cur.execute("SELECT file_hash FROM documents WHERE filepath = %s", (filepath,))
        row = cur.fetchone()
        if row:
            doc_id = row[0][:16]
            try:
                meili_index.delete_document(doc_id)
            except Exception:
                pass
        cur.execute("DELETE FROM documents WHERE filepath = %s", (filepath,))
    db_conn.commit()
    log.info(f"Gel√∂scht aus Index: {filepath}")


# --- Dateisystem-Watcher ---

class EduFileHandler(FileSystemEventHandler):
    def __init__(self, db_conn, meili_index):
        self.db_conn = db_conn
        self.meili_index = meili_index

    def on_created(self, event):
        if not event.is_directory:
            process_file(event.src_path, self.db_conn, self.meili_index)

    def on_modified(self, event):
        if not event.is_directory:
            process_file(event.src_path, self.db_conn, self.meili_index)

    def on_deleted(self, event):
        if not event.is_directory:
            delete_from_index(event.src_path, self.db_conn, self.meili_index)

    def on_moved(self, event):
        if not event.is_directory:
            delete_from_index(event.src_path, self.db_conn, self.meili_index)
            process_file(event.dest_path, self.db_conn, self.meili_index)


# --- Initiale Indizierung ---

def initial_indexing(db_conn, meili_index):
    """Alle Dateien in den Watch-Verzeichnissen einmalig indizieren."""
    log.info("Starte initiale Indizierung...")
    count = 0
    for watch_dir in WATCH_DIRS:
        watch_path = Path(watch_dir.strip())
        if not watch_path.exists():
            log.warning(f"Verzeichnis existiert nicht: {watch_dir}")
            continue
        for fpath in watch_path.rglob("*"):
            if fpath.is_file() and fpath.suffix.lower() in SUPPORTED_EXTENSIONS:
                try:
                    process_file(str(fpath), db_conn, meili_index)
                    count += 1
                except Exception as e:
                    log.error(f"Fehler bei {fpath}: {e}")
    log.info(f"Initiale Indizierung abgeschlossen: {count} Dateien verarbeitet.")


# --- Hauptprogramm ---

if __name__ == "__main__":
    log.info("=== Edu-Search Indexer gestartet ===")
    log.info(f"Watch-Dirs: {WATCH_DIRS}")
    log.info(f"Ollama: {OLLAMA_URL} (Modell: {OLLAMA_MODEL})")
    log.info(f"Tika: {TIKA_URL}")
    log.info(f"MeiliSearch: {MEILI_URL}")
    log.info(f"PostgreSQL: {DB_HOST}:{DB_PORT}/{DB_NAME}")

    # Verbindungen aufbauen
    db_conn = get_db_connection()
    meili_index = get_meili_client()

    # Initiale Indizierung
    initial_indexing(db_conn, meili_index)

    # Dateisystem-Watcher starten (PollingObserver wegen virtiofs)
    handler = EduFileHandler(db_conn, meili_index)
    observer = PollingObserver(timeout=POLL_INTERVAL)
    for watch_dir in WATCH_DIRS:
        d = watch_dir.strip()
        if os.path.exists(d):
            observer.schedule(handler, d, recursive=True)
            log.info(f"√úberwache: {d}")

    observer.start()
    log.info(f"Dateisystem-Watcher aktiv (Polling alle {POLL_INTERVAL}s)")

    try:
        while True:
            time.sleep(1)
    except KeyboardInterrupt:
        observer.stop()
        log.info("Shutdown angefordert...")
    observer.join()
    db_conn.close()
    log.info("=== Edu-Search Indexer beendet ===")
```

> **HINWEIS zum Indexer-Skript:** Dies ist ein funktionsf√§higer Entwurf. Vor dem
> produktiven Einsatz sollten folgende Punkte erg√§nzt werden:
> - Retry-Logik bei Ollama-Timeouts (GPU kann unter Last stehen)
> - Rate-Limiting f√ºr Ollama-Anfragen (max. 1 Request gleichzeitig)
> - Graceful Shutdown mit Signal-Handling
> - Metriken-Export (z.B. Anzahl indexierter Dateien, Fehlerrate)
> - Health-Check Endpoint f√ºr Monitoring

---

## 7. Phase 3 ‚Äì Web-UI f√ºr Ina (1 Wochenende)

### 7.1 Nginx als statischer Server

**Datei: `hosts/HL-1-MRZ-HOST-01/guests/edu-search/webui.nix`**

```nix
# Statische Web-UI f√ºr die Unterrichtsmaterial-Suche
{ config, pkgs, lib, globals, ... }: let
  meiliPort = 7700;
  meiliHost = "127.0.0.1";
  webPort = 8080;

  # Statische Web-UI Dateien als Nix-Derivation
  eduWebUI = pkgs.runCommand "edu-search-webui" {} ''
    mkdir -p $out
    cp ${./webui/index.html} $out/index.html
    cp ${./webui/style.css} $out/style.css
    cp ${./webui/app.js} $out/app.js
  '';
in {
  services.nginx = {
    enable = true;

    virtualHosts."edu-search" = {
      listen = [{ addr = "0.0.0.0"; port = webPort; }];
      root = "${eduWebUI}";

      locations."/" = {
        index = "index.html";
        tryFiles = "$uri $uri/ /index.html";
      };

      # MeiliSearch als API-Proxy (damit die SPA direkt suchen kann)
      locations."/meili/" = {
        proxyPass = "http://${meiliHost}:${toString meiliPort}/";
        extraConfig = ''
          proxy_set_header Host $host;
          proxy_set_header X-Real-IP $remote_addr;
          # CORS f√ºr lokale Entwicklung
          add_header Access-Control-Allow-Origin *;
          add_header Access-Control-Allow-Methods "GET, POST, OPTIONS";
          add_header Access-Control-Allow-Headers "Content-Type, Authorization";
        '';
      };
    };
  };

  networking.firewall.allowedTCPPorts = [ webPort ];
}
```

### 7.2 HTML-Suchoberfl√§che

**Datei: `hosts/HL-1-MRZ-HOST-01/guests/edu-search/webui/index.html`**

```html
<!DOCTYPE html>
<html lang="de">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Unterrichtsmaterial-Suche</title>
  <link rel="stylesheet" href="style.css">
</head>
<body>
  <header>
    <h1>üìö Unterrichtsmaterial-Suche</h1>
  </header>

  <main>
    <div class="search-bar">
      <input type="text" id="search-input" placeholder="Suche nach Thema, Inhalt, Dateiname..."
             autofocus autocomplete="off">
    </div>

    <div class="filters">
      <select id="filter-fach">
        <option value="">Alle F√§cher</option>
        <option value="Englisch">Englisch</option>
        <option value="Spanisch">Spanisch</option>
        <option value="Sonstige">Sonstige</option>
      </select>

      <select id="filter-klasse">
        <option value="">Alle Klassen</option>
        <option value="5">Klasse 5</option>
        <option value="6">Klasse 6</option>
        <option value="7">Klasse 7</option>
        <option value="8">Klasse 8</option>
        <option value="9">Klasse 9</option>
        <option value="10">Klasse 10</option>
        <option value="11">Klasse 11</option>
        <option value="12">Klasse 12</option>
        <option value="13">Klasse 13</option>
      </select>

      <select id="filter-typ">
        <option value="">Alle Typen</option>
        <option value="Arbeitsblatt">Arbeitsblatt</option>
        <option value="Pr√§sentation">Pr√§sentation</option>
        <option value="Test">Test</option>
        <option value="Klausur">Klausur</option>
        <option value="Audio">Audio</option>
        <option value="Video">Video</option>
        <option value="Sonstiges">Sonstiges</option>
      </select>

      <select id="filter-niveau">
        <option value="">Alle Niveaus</option>
        <option value="A1">A1</option>
        <option value="A2">A2</option>
        <option value="B1">B1</option>
        <option value="B2">B2</option>
        <option value="C1">C1</option>
        <option value="C2">C2</option>
      </select>
    </div>

    <div id="stats" class="stats"></div>

    <div id="results" class="results">
      <p class="placeholder">Gib einen Suchbegriff ein oder w√§hle einen Filter...</p>
    </div>
  </main>

  <script src="app.js"></script>
</body>
</html>
```

### 7.3 CSS-Styling

**Datei: `hosts/HL-1-MRZ-HOST-01/guests/edu-search/webui/style.css`**

```css
/* Edu-Search ‚Äì Einfaches, √ºbersichtliches Design */
* { box-sizing: border-box; margin: 0; padding: 0; }

body {
  font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Helvetica, sans-serif;
  background: #f5f7fa;
  color: #333;
  max-width: 960px;
  margin: 0 auto;
  padding: 20px;
}

header {
  text-align: center;
  margin-bottom: 24px;
}

header h1 {
  font-size: 1.8em;
  color: #2c3e50;
}

.search-bar {
  margin-bottom: 16px;
}

.search-bar input {
  width: 100%;
  padding: 14px 20px;
  font-size: 1.1em;
  border: 2px solid #ddd;
  border-radius: 8px;
  outline: none;
  transition: border-color 0.2s;
}

.search-bar input:focus {
  border-color: #3498db;
}

.filters {
  display: flex;
  gap: 12px;
  margin-bottom: 16px;
  flex-wrap: wrap;
}

.filters select {
  flex: 1;
  min-width: 140px;
  padding: 10px 12px;
  font-size: 0.95em;
  border: 1px solid #ddd;
  border-radius: 6px;
  background: white;
  cursor: pointer;
}

.stats {
  font-size: 0.85em;
  color: #888;
  margin-bottom: 12px;
}

.results {
  display: flex;
  flex-direction: column;
  gap: 10px;
}

.result-card {
  background: white;
  border: 1px solid #e0e0e0;
  border-radius: 8px;
  padding: 16px;
  cursor: pointer;
  transition: box-shadow 0.2s, border-color 0.2s;
  text-decoration: none;
  color: inherit;
  display: block;
}

.result-card:hover {
  box-shadow: 0 2px 8px rgba(0,0,0,0.1);
  border-color: #3498db;
}

.result-card .filename {
  font-weight: 600;
  font-size: 1.05em;
  color: #2c3e50;
  margin-bottom: 6px;
}

.result-card .meta {
  display: flex;
  gap: 12px;
  flex-wrap: wrap;
  font-size: 0.85em;
  color: #666;
}

.result-card .meta .tag {
  background: #ecf0f1;
  padding: 2px 8px;
  border-radius: 4px;
}

.result-card .meta .tag.fach-englisch { background: #d5f5e3; color: #1e8449; }
.result-card .meta .tag.fach-spanisch { background: #fdebd0; color: #b9770e; }
.result-card .thema {
  font-size: 0.9em;
  color: #555;
  margin-top: 4px;
}

.placeholder {
  text-align: center;
  color: #aaa;
  padding: 40px;
  font-size: 1.1em;
}
```

### 7.4 JavaScript-Suchlogik

**Datei: `hosts/HL-1-MRZ-HOST-01/guests/edu-search/webui/app.js`**

```javascript
// Edu-Search Frontend ‚Äì verbindet sich mit MeiliSearch via /meili/ Proxy
const MEILI_URL = "/meili";
const INDEX_NAME = "edu_documents";

const searchInput = document.getElementById("search-input");
const filterFach = document.getElementById("filter-fach");
const filterKlasse = document.getElementById("filter-klasse");
const filterTyp = document.getElementById("filter-typ");
const filterNiveau = document.getElementById("filter-niveau");
const resultsDiv = document.getElementById("results");
const statsDiv = document.getElementById("stats");

let debounceTimer = null;

// Suche ausf√ºhren
async function doSearch() {
  const query = searchInput.value.trim();
  const filters = [];

  if (filterFach.value) filters.push(`fach = "${filterFach.value}"`);
  if (filterKlasse.value) filters.push(`klasse = "${filterKlasse.value}"`);
  if (filterTyp.value) filters.push(`typ = "${filterTyp.value}"`);
  if (filterNiveau.value) filters.push(`niveau = "${filterNiveau.value}"`);

  // Mindestens Query oder Filter n√∂tig
  if (!query && filters.length === 0) {
    resultsDiv.innerHTML = '<p class="placeholder">Gib einen Suchbegriff ein oder w√§hle einen Filter...</p>';
    statsDiv.textContent = "";
    return;
  }

  try {
    const body = {
      q: query || "",
      filter: filters.length > 0 ? filters.join(" AND ") : undefined,
      limit: 50,
      attributesToHighlight: ["filename", "thema"],
      highlightPreTag: "<mark>",
      highlightPostTag: "</mark>",
    };

    const resp = await fetch(`${MEILI_URL}/indexes/${INDEX_NAME}/search`, {
      method: "POST",
      headers: { "Content-Type": "application/json" },
      body: JSON.stringify(body),
    });

    if (!resp.ok) throw new Error(`HTTP ${resp.status}`);
    const data = await resp.json();
    renderResults(data);
  } catch (err) {
    resultsDiv.innerHTML = `<p class="placeholder">Fehler bei der Suche: ${err.message}</p>`;
    statsDiv.textContent = "";
  }
}

// Ergebnisse rendern
function renderResults(data) {
  const hits = data.hits || [];
  statsDiv.textContent = `${data.estimatedTotalHits || hits.length} Ergebnis(se) in ${data.processingTimeMs}ms`;

  if (hits.length === 0) {
    resultsDiv.innerHTML = '<p class="placeholder">Keine Ergebnisse gefunden.</p>';
    return;
  }

  resultsDiv.innerHTML = hits.map(hit => {
    const hl = hit._formatted || hit;
    const fachClass = (hit.fach || "").toLowerCase().includes("englisch") ? "fach-englisch"
                    : (hit.fach || "").toLowerCase().includes("spanisch") ? "fach-spanisch" : "";
    return `
      <a class="result-card" href="${hit.smb_url || '#'}" title="Klicke um die Datei zu √∂ffnen">
        <div class="filename">${hl.filename || hit.filename}</div>
        <div class="meta">
          ${hit.fach ? `<span class="tag ${fachClass}">${hit.fach}</span>` : ""}
          ${hit.klasse && hit.klasse !== "unbekannt" ? `<span class="tag">Klasse ${hit.klasse}</span>` : ""}
          ${hit.typ && hit.typ !== "Sonstiges" ? `<span class="tag">${hit.typ}</span>` : ""}
          ${hit.niveau && hit.niveau !== "unbekannt" ? `<span class="tag">${hit.niveau}</span>` : ""}
          ${hit.file_extension ? `<span class="tag">${hit.file_extension}</span>` : ""}
        </div>
        ${hit.thema ? `<div class="thema">${hl.thema || hit.thema}</div>` : ""}
      </a>
    `;
  }).join("");
}

// Event-Listener mit Debounce
function onInputChange() {
  clearTimeout(debounceTimer);
  debounceTimer = setTimeout(doSearch, 250);
}

searchInput.addEventListener("input", onInputChange);
filterFach.addEventListener("change", doSearch);
filterKlasse.addEventListener("change", doSearch);
filterTyp.addEventListener("change", doSearch);
filterNiveau.addEventListener("change", doSearch);

// Beim Laden: leere Suche zeigen (alle Dokumente)
// doSearch();
```

> **Hinweis zu `smb://` Links:** Windows √∂ffnet `smb://`-Links aus dem Browser normalerweise
> nicht direkt. Alternativen:
> - Link als `file:///\\HL-3-RZ-SMB-01\shares\...` formatieren (Windows UNC-Pfad)
> - Kleines Browser-Plugin oder ein `smb://`-Handler registrieren
> - "Pfad kopieren"-Button statt direktem Link, Ina f√ºgt ihn im Explorer ein
> - Am einfachsten: `\\HL-3-RZ-SMB-01\shares\...` als kopierbaren Text anzeigen

---

## 8. Phase 4 ‚Äì Backup & Monitoring

### 8.1 Backup-Strategie √úbersicht

| Komponente | Wo | Backup n√∂tig? | Methode |
|---|---|---|---|
| **NVIDIA-Treiber** | HOST-01 | ‚ùå | Im Nix-Store, deklarativ |
| **Ollama Modelle** | HOST-01 `/var/lib/private/ollama` | ‚ö†Ô∏è Optional | K√∂nnen via `ollama pull` wiederhergestellt werden |
| **PostgreSQL** | MicroVM `/persist/var/lib/postgresql` | ‚úÖ **Ja** | `pg_dump` ‚Üí Restic ‚Üí OneDrive/rclone |
| **MeiliSearch** | MicroVM `/persist/var/lib/meilisearch` | ‚ö†Ô∏è Optional | Kann aus PostgreSQL + NAS rebuilt werden |
| **Indexer State** | MicroVM `/persist/var/lib/edu-indexer` | ‚ö†Ô∏è Optional | `state.json` ‚Äì Re-Index jederzeit m√∂glich |
| **Python-Skript** | Nix-Repo (Git) | ‚úÖ | Git-Versionierung |
| **Web-UI** | Nix-Repo (Git) | ‚úÖ | Git-Versionierung |
| **NAS-Dateien** | Samba MicroVM | ‚úÖ | Bereits durch bestehende Restic-Backups abgedeckt |
| **Nix-Konfiguration** | Git-Repo | ‚úÖ | Git + Forgejo |

### 8.2 Restic-Backup f√ºr edu-search

**Datei: `hosts/HL-1-MRZ-HOST-01/guests/edu-search/backup.nix`**

```nix
# Restic-Backup f√ºr Edu-Search Metadaten (PostgreSQL)
{ config, pkgs, lib, globals, secretsPath, ... }: {

  # --- Secrets ---
  age.secrets."rclone.conf" = {
    file = secretsPath + "/hosts/HL-1-MRZ-HOST-01/guests/samba/rclone.conf.age";
    mode = "440";
  };
  age.secrets.restic-edu-search = {
    file = secretsPath + "/hosts/HL-1-MRZ-HOST-01/guests/edu-search/restic-password.age";
    mode = "440";
  };
  age.secrets.ntfy-alert-pass = {
    file = secretsPath + "/ntfy-sh/alert-pass.age";
    mode = "440";
  };
  age.secrets.edu-search-hc-ping = {
    file = secretsPath + "/hosts/HL-1-MRZ-HOST-01/guests/edu-search/healthchecks-ping.age";
    mode = "440";
  };

  # --- PostgreSQL Dump vor Backup ---
  systemd.services.edu-search-pg-dump = {
    description = "Dump Edu-Search PostgreSQL database before backup";
    serviceConfig = {
      Type = "oneshot";
      User = "postgres";
      ExecStart = ''
        ${pkgs.postgresql_16}/bin/pg_dump \
          --format=custom \
          --file=/var/lib/edu-search-backup/edu_search.pgdump \
          edu_search
      '';
    };
  };

  systemd.tmpfiles.settings."10-edu-backup" = {
    "/var/lib/edu-search-backup".d = {
      user = "postgres";
      group = "postgres";
      mode = "0750";
    };
  };

  # --- Restic Backup ---
  services.restic.backups = let
    ntfy_pass = "$(cat ${config.age.secrets.ntfy-alert-pass.path})";
    ntfy_url = "https://${globals.services.ntfy-sh.domain}/backups";

    script-post = ''
      pingKey="$(cat ${config.age.secrets.edu-search-hc-ping.path})";
      if [ $EXIT_STATUS -ne 0 ]; then
        ${pkgs.curl}/bin/curl -u alert:${ntfy_pass} \
          -H 'Title: Backup (edu-search) failed!' \
          -H 'Tags: backup,restic,edu-search' \
          -d "Restic edu-search backup error!" '${ntfy_url}'
        ${pkgs.curl}/bin/curl -m 10 --retry 5 --retry-connrefused \
          "https://health.czichy.com/ping/$pingKey/backup-edu-search/fail"
      else
        ${pkgs.curl}/bin/curl -m 10 --retry 5 --retry-connrefused \
          "https://health.czichy.com/ping/$pingKey/backup-edu-search"
      fi
    '';
  in {
    edu-search-backup = {
      initialize = true;
      repository = "rclone:onedrive_nas:/backup/${config.networking.hostName}-edu-search";

      paths = [
        "/var/lib/edu-search-backup"          # PostgreSQL Dump
        "/var/lib/edu-indexer/state.json"      # Indexer-Status (optional)
      ];

      exclude = [];
      passwordFile = config.age.secrets.restic-edu-search.path;
      rcloneConfigFile = config.age.secrets."rclone.conf".path;
      backupCleanupCommand = script-post;

      # pg_dump muss vorher laufen
      backupPrepareCommand = ''
        systemctl start edu-search-pg-dump.service
      '';

      pruneOpts = [
        "--keep-daily 7"
        "--keep-weekly 4"
        "--keep-monthly 6"
        "--keep-yearly 2"
      ];

      timerConfig = {
        OnCalendar = "*-*-* 02:00:00";  # Nachts um 2 Uhr
      };
    };
  };

  # Backup-Verzeichnis persistent
  environment.persistence."/persist".directories = [
    {
      directory = "/var/lib/edu-search-backup";
      user = "postgres";
      group = "postgres";
      mode = "0750";
    }
  ];
  # Needed so we don't run out of tmpfs space
  environment.persistence."/state".directories = [
    {
      directory = "/var/cache/edu-search";
      user = "root";
      group = "root";
      mode = "0750";
    }
  ];
}
```

### 8.3 Rebuild-Strategie (Disaster Recovery)

Falls die MicroVM oder Daten verloren gehen:

1. **Nix-Konfiguration** ‚Üí `nixos-rebuild` erstellt die MicroVM neu
2. **PostgreSQL** ‚Üí Restic-Restore des `pg_dump` ‚Üí `pg_restore`
3. **MeiliSearch** ‚Üí Muss NICHT restored werden! Der Indexer kann MeiliSearch komplett
   aus PostgreSQL-Daten neu bef√ºllen (ein Re-Index-Skript sollte als Management-Command
   bereitgestellt werden)
4. **Ollama-Modelle** ‚Üí `ollama pull mistral:7b` (5 Minuten Download)
5. **NAS-Dateien** ‚Üí Bereits durch Samba-Restic-Backups gesch√ºtzt

### 8.4 Monitoring

```nix
# In edu-search.nix erg√§nzen:
globals.monitoring.http.edu-search = {
  url = "http://${globals.net.vlan40.hosts."HL-3-RZ-EDU-01".ipv4}:8080";
  expectedBodyRegex = "Unterrichtsmaterial";
  network = "vlan40";
};

globals.monitoring.tcp.edu-search-meili = {
  host = globals.net.vlan40.hosts."HL-3-RZ-EDU-01".ipv4;
  port = 7700;
  network = "vlan40";
};
```

---

## 9. Netzwerk & Globals

### 9.1 √Ñnderungen in `globals.nix`

```nix
# In vlan40.hosts hinzuf√ºgen:
hosts.HL-3-RZ-EDU-01.id = 114;    # Edu-Search MicroVM
```

### 9.2 √Ñnderungen in `guests.nix`

```nix
# Neue MicroVM registrieren (nach den bestehenden mkMicrovm-Aufrufen):
// mkMicrovm "edu-search" "HL-3-RZ-EDU-01" "enp38s0" "02:08:27:ee:9e:16" "vlan40" {
  enableSharedDataset = true;    # /shared ‚Üí Inas Syncthing-Dateien
  enableStorageDataset = true;   # /storage ‚Üí Bibliothek, Dokumente
}
```

### 9.3 Neue systemd.tmpfiles f√ºr HOST-01

```nix
# In guests.nix, im systemd.tmpfiles.settings-Block:
"10-edu-search-shares" = {
  "/storage/shares/bibliothek".d = {
    user = "root";
    group = "root";
    mode = "0777";
  };
};
```

### 9.4 Netzwerkdiagramm

```text
vlan40 (10.15.40.0/24)
‚îú‚îÄ‚îÄ .10   HL-1-MRZ-HOST-01      (Ollama :11434)
‚îú‚îÄ‚îÄ .11   HL-3-RZ-SMB-01        (Samba ‚Äì NAS-Dateien)
‚îú‚îÄ‚îÄ .13   HL-3-RZ-SYNC-01       (Syncthing Christian)
‚îú‚îÄ‚îÄ .113  HL-3-RZ-SYNC-02       (Syncthing Ina)
‚îú‚îÄ‚îÄ .114  HL-3-RZ-EDU-01  ‚Üê NEU (Edu-Search: Tika+PG+Meili+WebUI)
‚îú‚îÄ‚îÄ .99   HL-3-MRZ-FW-01        (Gateway/Firewall)
‚îî‚îÄ‚îÄ ...   (weitere bestehende VMs)

Datenfl√ºsse:
  EDU-01 ‚îÄ‚îÄHTTP:11434‚îÄ‚îÄ‚Üí HOST-01 (Ollama API)
  EDU-01 ‚îÄ‚îÄvirtiofs‚îÄ‚îÄ‚îÄ‚îÄ‚Üí HOST-01 ZFS Storage (NAS-Shares, read-only)
  EDU-01 ‚îÄ‚îÄHTTP:8080‚îÄ‚îÄ‚îÄ‚Üí HOST-02 Caddy ‚Üí Internet (edu.czichy.com)
  Inas PC ‚îÄ‚îÄSMB:445‚îÄ‚îÄ‚îÄ‚îÄ‚Üí SMB-01 (NAS lesen/schreiben)
  Inas PC ‚îÄ‚îÄHTTPS‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚Üí edu.czichy.com (Suche)
```

---

## 10. Offene Fragen & Risiken

### Offene Fragen (vor Implementierung kl√§ren)

| # | Frage | Status | Auswirkung |
|---|---|---|---|
| 1 | **Welche NVIDIA-GPU ist in HOST-01?** | ‚úÖ **GTX 1660 SUPER** (TU116, 6GB VRAM, PCI `2d:00.0`) | `nvidiaPackages.stable`, `open = false`, max 7B-8B Modelle |
| 2 | **Wie viel RAM hat HOST-01?** | ‚úÖ **64GB** (34GB frei) | Mehr als genug f√ºr alles ‚Äì edu-search MicroVM kann 6GB bekommen |
| 3 | **Ist `pkgs.apacheTika` in nixpkgs verf√ºgbar?** | ‚úÖ **Nein** ‚Äì `fetchurl` des JAR nutzen | `python3Packages.tika` (3.1.0) und `tika-client` (0.10.0) existieren als Python-Bindings. Tika-Server-JAR via `fetchurl` beziehen, mit `jdk21_headless` ausf√ºhren |
| 4 | **MeiliSearch Master-Key:** Soll er via agenix verwaltet werden? | ‚ùì Offen | Aktuell Platzhalter ‚Äì f√ºr Produktion Secret n√∂tig |
| 5 | **Sollen ALLE Ina-Ordner indexiert werden?** Oder nur `/schule/`? | ‚ùì Offen | Bestimmt Umfang und Dauer der initialen Indexierung |
| 6 | **smb:// Links im Browser:** Funktioniert das unter Windows? | ‚ùì Offen | Evtl. UNC-Pfad (`\\server\share\...`) stattdessen oder Kopier-Button |
| 7 | **MAC-Adresse f√ºr edu-search MicroVM:** Ist `02:08:27:ee:9e:16` frei? | ‚ùì Offen | Muss gegen bestehende MACs in `guests.nix` gepr√ºft werden |
| 8 | **Bestehende `meilisearch.nix` und `ai.nix`:** Entfernen oder behalten? | ‚ùì Offen | ai.nix refactoren (Ollama raus), meilisearch.nix durch edu-search ersetzen |
| 9 | **restic Secrets:** Existiert bereits ein Secret-Pfad f√ºr edu-search? | ‚ùì Offen | Neue agenix-Secrets m√ºssen generiert und eingecheckt werden |
| 10 | **Domain `edu.czichy.com`:** DNS-Record bei Cloudflare anlegen? | ‚ùì Offen | Muss vor HTTPS-Zugriff konfiguriert sein |

### Risiken

| Risiko | Wahrscheinlichkeit | Gegenma√ünahme |
|---|---|---|
| **Ollama auf CPU statt GPU** (falscher Treiber) | Niedrig (HW best√§tigt) | GPU-Test VOR restlicher Implementierung: `nvidia-smi` + `ollama run mistral:7b "test"` |
| **Tika-JAR nicht in nixpkgs** | Mittel | Fallback: `fetchurl` des offiziellen JAR von Apache Mirror |
| **virtiofs sendet kein inotify** | Hoch | Bereits ber√ºcksichtigt: `PollingObserver` statt inotify-basiertem Watcher |
| **Ollama-Klassifikation ungenau** | Mittel | Prompt iterativ verbessern, ggf. Few-Shot-Beispiele hinzuf√ºgen |
| **RAM-Engpass auf HOST-01** | ‚úÖ Kein Risiko (64GB) | edu-search MicroVM mit 6GB, 34GB frei nach aktuellen VMs |
| **Ina findet UI nicht intuitiv** | Niedrig | Fr√ºhzeitig Feedback einholen, UI ist simpel gehalten |
| **Gro√üe initiale Indexierung** (1000+ Dateien) | Mittel | Rate-Limiting einbauen, ggf. √ºber Nacht laufen lassen |

### Priorisierter Aktionsplan

```text
SOFORT (vor Code):
  ‚úÖ lspci | grep -i nvidia  ‚Üí  GTX 1660 SUPER (TU116, 6GB VRAM)
  ‚úÖ free -h                 ‚Üí  64GB RAM, 34GB frei
  ‚úÖ nix search tika         ‚Üí  pkgs.apacheTika existiert NICHT; python3Packages.tika (3.1.0) + tika-client (0.10.0) vorhanden; JAR via fetchurl beziehen
  ‚úÖ MAC-Adresse             ‚Üí  02:08:27:ee:9e:16 ist frei (Muster 02:XX:27:ee:9e:16, XX=01-07 belegt)

PHASE 1 ‚Äì Fundament (Wochenende 1):
  ‚ñ° modules/gpu.nix erstellen (NVIDIA-Treiber)
  ‚ñ° modules/ollama.nix erstellen (Ollama nativ auf HOST-01)
  ‚ñ° modules/default.nix anpassen (Imports)
  ‚ñ° nixos-rebuild, nvidia-smi testen
  ‚ñ° ollama pull mistral:7b, Testprompt ausf√ºhren
  ‚ñ° globals.nix: HL-3-RZ-EDU-01.id = 114 eintragen
  ‚ñ° guests.nix: mkMicrovm "edu-search" eintragen
  ‚ñ° guests/edu-search.nix Grundkonfiguration erstellen
  ‚ñ° edu-search/tika.nix erstellen
  ‚ñ° edu-search/postgresql.nix erstellen
  ‚ñ° MicroVM starten, Tika + PostgreSQL testen

PHASE 2 ‚Äì Suche & Indexierung (Wochenende 2):
  ‚ñ° edu-search/meilisearch.nix erstellen
  ‚ñ° edu-search/indexer.py fertigstellen & testen
  ‚ñ° edu-search/indexer.nix erstellen (systemd Service)
  ‚ñ° Testlauf: 10 Dateien manuell indexieren
  ‚ñ° MeiliSearch-API mit curl testen (Suche + Filter)
  ‚ñ° Ollama-Prompt mit echten Unterrichtsmaterialien iterieren
  ‚ñ° Initiale Indexierung aller NAS-Dateien √ºber Nacht laufen lassen

PHASE 3 ‚Äì Web-UI (Wochenende 3):
  ‚ñ° edu-search/webui/ HTML+CSS+JS erstellen
  ‚ñ° edu-search/webui.nix Nginx-Konfiguration
  ‚ñ° Caddy Reverse Proxy auf HOST-02 konfigurieren
  ‚ñ° DNS-Record edu.czichy.com anlegen
  ‚ñ° Ina testen lassen, Feedback einarbeiten
  ‚ñ° smb://-Links vs. UNC-Pfade auf Windows testen

PHASE 4 ‚Äì Backup & H√§rten (parallel):
  ‚ñ° agenix-Secrets generieren (restic-password, meili-key, hc-ping)
  ‚ñ° edu-search/backup.nix erstellen
  ‚ñ° Restic-Backup manuell testen (init + backup + restore)
  ‚ñ° Monitoring-Eintr√§ge in globals hinzuf√ºgen
  ‚ñ° MeiliSearch Master-Key von Platzhalter auf agenix umstellen
  ‚ñ° ai.nix refactoren (Ollama entfernen, Open-WebUI ‚Üí HOST-01:11434)
  ‚ñ° Alte meilisearch.nix + meilisearch/ Ordner aufr√§umen/entfernen

OPTIONAL / LATER:
  ‚ñ° Re-Index-Management-Command (PostgreSQL ‚Üí MeiliSearch rebuild)
  ‚ñ° Metriken-Export (Prometheus) f√ºr den Indexer
  ‚ñ° Health-Check-Endpoint im Indexer
  ‚ñ° Few-Shot-Beispiele im Ollama-Prompt f√ºr bessere Klassifikation
  ‚ñ° Vorschau-Thumbnails in der Web-UI (PDF erste Seite etc.)
  ‚ñ° Automatische Sprach-Erkennung (Englisch/Spanisch/Deutsch) als Fallback
```

---

## Zusammenfassung

| Phase | Aufwand | Ergebnis |
|---|---|---|
| **Phase 1** | 1-2 Wochenenden | GPU + Ollama + Tika + PostgreSQL laufen |
| **Phase 2** | 1 Wochenende | Alle Dateien indexiert, MeiliSearch durchsuchbar |
| **Phase 3** | 1 Wochenende | Ina kann im Browser suchen und Dateien √∂ffnen |
| **Phase 4** | Parallel | Backup gesichert, Monitoring aktiv |

**Gesamtaufwand:** ~3-4 Wochenenden

**Kernprinzip:** Die Originaldateien auf dem NAS werden **niemals ver√§ndert**. Das System
liest nur, extrahiert, klassifiziert und indexiert. Ina arbeitet weiterhin ganz normal mit
ihren Dateien √ºber Windows/Samba. Die Websuche ist ein reiner Lesezugriff darauf.